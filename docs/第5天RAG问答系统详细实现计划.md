# ç¬¬5å¤©ï¼šRAGé—®ç­”ç³»ç»Ÿè¯¦ç»†å®ç°è®¡åˆ’

## ğŸ¯ æ€»ä½“ç›®æ ‡
å®ç°åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿä¸æ–‡çŒ®è¿›è¡Œè‡ªç„¶è¯­è¨€å¯¹è¯ï¼Œè·å¾—å‡†ç¡®çš„ç­”æ¡ˆå’Œå¼•ç”¨æ¥æºã€‚

## ğŸ“‹ å®ç°ä¼˜å…ˆçº§

### æ ¸å¿ƒåŠŸèƒ½ï¼ˆå¿…é¡»å®Œæˆï¼‰â­â­â­
1. RAGæ£€ç´¢å¼•æ“
2. AIé—®ç­”æ¥å£
3. å¯¹è¯å†å²ç®¡ç†
4. å¼•ç”¨æ¥æºè¿½è¸ª

### å¢å¼ºåŠŸèƒ½ï¼ˆé‡è¦ï¼‰â­â­
1. é¢„è®¾é—®é¢˜æ¨è
2. ç­”æ¡ˆè´¨é‡è¯„ä¼°
3. æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜
4. é”™è¯¯å¤„ç†å’Œé™çº§

### æ‰©å±•åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰â­
1. æµå¼å“åº”
2. å¤šè½®å¯¹è¯ä¼˜åŒ–
3. ä¸ªæ€§åŒ–é—®é¢˜æ¨è
4. ç­”æ¡ˆè¯„åˆ†æœºåˆ¶

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è®¾è®¡

### 1. æ ¸å¿ƒç»„ä»¶æ¶æ„
```
ç”¨æˆ·é—®é¢˜ â†’ é—®é¢˜ç†è§£ â†’ ç›¸å…³æ€§æ£€ç´¢ â†’ ä¸Šä¸‹æ–‡æ„å»º â†’ AIç”Ÿæˆ â†’ ç­”æ¡ˆè¿”å›
    â†“           â†“            â†“           â†“          â†“         â†“
é—®é¢˜é¢„å¤„ç†   Embedding    å‘é‡æœç´¢    æç¤ºè¯æ„å»º   LLMè°ƒç”¨   åå¤„ç†
```

### 2. æ•°æ®æµè®¾è®¡
```
Input: {question, literature_id, conversation_history}
  â†“
Step 1: é—®é¢˜é¢„å¤„ç†å’ŒEmbeddingç”Ÿæˆ
  â†“
Step 2: å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£å—
  â†“
Step 3: ä¸Šä¸‹æ–‡é‡æ’åºå’Œç­›é€‰
  â†“
Step 4: æç¤ºè¯æ¨¡æ¿æ„å»º
  â†“
Step 5: LLMç”Ÿæˆç­”æ¡ˆ
  â†“
Output: {answer, sources, confidence, reasoning}
```

---

## ğŸ“ æ–‡ä»¶ç»“æ„è§„åˆ’

```
app/utils/
â”œâ”€â”€ rag_service.py          # RAGæ ¸å¿ƒæœåŠ¡
â”œâ”€â”€ conversation_manager.py # å¯¹è¯å†å²ç®¡ç†
â”œâ”€â”€ prompt_builder.py       # æç¤ºè¯æ„å»ºå™¨
â”œâ”€â”€ answer_processor.py     # ç­”æ¡ˆåå¤„ç†
â””â”€â”€ cache_manager.py        # ç¼“å­˜ç®¡ç†

app/models/
â”œâ”€â”€ conversation.py         # å¯¹è¯æ¨¡å‹
â””â”€â”€ qa_session.py          # é—®ç­”ä¼šè¯æ¨¡å‹

app/routers/
â””â”€â”€ ai_chat.py             # AIèŠå¤©è·¯ç”±

tests/
â”œâ”€â”€ test_rag_service.py
â”œâ”€â”€ test_conversation.py
â””â”€â”€ test_ai_chat_api.py
```

---

## ğŸ› ï¸ è¯¦ç»†å®ç°è®¡åˆ’

### Phase 1: RAGæ ¸å¿ƒæœåŠ¡å®ç° (90åˆ†é’Ÿ)

#### 1.1 åˆ›å»º `app/utils/rag_service.py` (45åˆ†é’Ÿ)
**åŠŸèƒ½æ¨¡å—ï¼š**
- é—®é¢˜ç†è§£å’Œé¢„å¤„ç†
- ç›¸å…³æ–‡æ¡£æ£€ç´¢
- ä¸Šä¸‹æ–‡æ„å»ºå’Œé‡æ’åº
- ç­”æ¡ˆç”Ÿæˆåè°ƒ

**å…³é”®ä¼˜åŒ–ï¼š**
- æ™ºèƒ½åˆ†å—åŒ¹é…ç®—æ³•
- åŠ¨æ€top-kè°ƒæ•´
- ä¸Šä¸‹æ–‡é•¿åº¦è‡ªé€‚åº”
- å¤šç­–ç•¥æ£€ç´¢èåˆ

```python
class RAGService:
    def __init__(self):
        self.embedding_service = embedding_service
        self.vector_store = vector_store
        self.llm_client = None
        self.cache = {}
    
    def process_question(self, question, literature_id, group_id, 
                        conversation_history=None, top_k=5):
        """å®Œæ•´çš„RAGé—®ç­”æµç¨‹"""
        
    def retrieve_relevant_chunks(self, question, literature_id, group_id, top_k):
        """æ™ºèƒ½æ£€ç´¢ç›¸å…³æ–‡æ¡£å—"""
        
    def rerank_chunks(self, chunks, question):
        """é‡æ’åºæ–‡æ¡£å—"""
        
    def build_context(self, chunks, max_tokens=3000):
        """æ„å»ºä¸Šä¸‹æ–‡"""
        
    def generate_answer(self, question, context, conversation_history):
        """ç”ŸæˆAIç­”æ¡ˆ"""
```

#### 1.2 åˆ›å»º `app/utils/prompt_builder.py` (25åˆ†é’Ÿ)
**åŠŸèƒ½æ¨¡å—ï¼š**
- åŠ¨æ€æç¤ºè¯æ¨¡æ¿
- ä¸Šä¸‹æ–‡æ ¼å¼åŒ–
- è§’è‰²å’Œçº¦æŸå®šä¹‰
- è¾“å‡ºæ ¼å¼è§„èŒƒ

**å…³é”®ä¼˜åŒ–ï¼š**
- æ¨¡æ¿ç‰ˆæœ¬æ§åˆ¶
- åŠ¨æ€é•¿åº¦è°ƒæ•´
- å¤šè¯­è¨€æ”¯æŒ
- é¢†åŸŸç‰¹åŒ–æ¨¡æ¿

```python
class PromptBuilder:
    def __init__(self):
        self.templates = self._load_templates()
        self.max_context_tokens = 3000
    
    def build_qa_prompt(self, question, context, conversation_history=None):
        """æ„å»ºé—®ç­”æç¤ºè¯"""
        
    def build_context_section(self, chunks):
        """æ„å»ºä¸Šä¸‹æ–‡éƒ¨åˆ†"""
        
    def format_conversation_history(self, history):
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        
    def optimize_prompt_length(self, prompt, max_tokens):
        """ä¼˜åŒ–æç¤ºè¯é•¿åº¦"""
```

#### 1.3 åˆ›å»º `app/utils/answer_processor.py` (20åˆ†é’Ÿ)
**åŠŸèƒ½æ¨¡å—ï¼š**
- ç­”æ¡ˆè´¨é‡æ£€éªŒ
- å¼•ç”¨æ¥æºæå–
- ç½®ä¿¡åº¦è®¡ç®—
- ç­”æ¡ˆæ ¼å¼åŒ–

**å…³é”®ä¼˜åŒ–ï¼š**
- å¼•ç”¨å‡†ç¡®æ€§éªŒè¯
- ç­”æ¡ˆå®Œæ•´æ€§æ£€æŸ¥
- å¤šç»´åº¦è´¨é‡è¯„åˆ†
- æ•æ„Ÿå†…å®¹è¿‡æ»¤

### Phase 2: å¯¹è¯ç®¡ç†ç³»ç»Ÿ (60åˆ†é’Ÿ)

#### 2.1 åˆ›å»º `app/utils/conversation_manager.py` (40åˆ†é’Ÿ)
**åŠŸèƒ½æ¨¡å—ï¼š**
- å¯¹è¯å†å²å­˜å‚¨
- ä¸Šä¸‹æ–‡å‹ç¼©
- å…³é”®ä¿¡æ¯æå–
- å¯¹è¯çŠ¶æ€ç®¡ç†

**å…³é”®ä¼˜åŒ–ï¼š**
- æ™ºèƒ½å†å²æˆªæ–­
- è¯­ä¹‰é‡è¦æ€§è¯„åˆ†
- ä¸»é¢˜è¿ç»­æ€§ä¿æŒ
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–

```python
class ConversationManager:
    def __init__(self):
        self.max_history_turns = 10
        self.max_tokens_per_turn = 500
        self.compression_threshold = 0.8
    
    def add_qa_turn(self, session_id, question, answer, sources):
        """æ·»åŠ é—®ç­”è½®æ¬¡"""
        
    def get_relevant_history(self, session_id, current_question, max_turns=5):
        """è·å–ç›¸å…³å†å²"""
        
    def compress_history(self, history):
        """å‹ç¼©å¯¹è¯å†å²"""
        
    def extract_key_context(self, history):
        """æå–å…³é”®ä¸Šä¸‹æ–‡"""
```

#### 2.2 åˆ›å»º `app/models/conversation.py` (20åˆ†é’Ÿ)
**æ•°æ®æ¨¡å‹ï¼š**
- QASession: é—®ç­”ä¼šè¯
- ConversationTurn: å¯¹è¯è½®æ¬¡
- ContextSummary: ä¸Šä¸‹æ–‡æ‘˜è¦

### Phase 3: APIæ¥å£å®ç° (75åˆ†é’Ÿ)

#### 3.1 åˆ›å»º `app/routers/ai_chat.py` (45åˆ†é’Ÿ)
**APIæ¥å£ï¼š**
- `POST /ai/ask` - æ™ºèƒ½é—®ç­”
- `GET /ai/preset-questions/{literature_id}` - é¢„è®¾é—®é¢˜
- `GET /ai/conversation/{session_id}` - è·å–å¯¹è¯å†å²
- `DELETE /ai/conversation/{session_id}` - æ¸…é™¤å¯¹è¯å†å²

**å…³é”®ä¼˜åŒ–ï¼š**
- å¼‚æ­¥å¤„ç†
- è¯·æ±‚é™æµ
- å‚æ•°éªŒè¯
- å“åº”ç¼“å­˜

```python
@router.post("/ask")
async def ask_question(
    request: QARequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æ™ºèƒ½é—®ç­”æ¥å£"""
    
@router.get("/preset-questions/{literature_id}")
async def get_preset_questions(
    literature_id: str,
    current_user: User = Depends(get_current_user)
):
    """è·å–é¢„è®¾é—®é¢˜"""
```

#### 3.2 åˆ›å»ºæ•°æ®æ¨¡å‹ (15åˆ†é’Ÿ)
```python
class QARequest(BaseModel):
    question: str = Field(..., min_length=1, max_length=1000)
    literature_id: str
    session_id: Optional[str] = None
    max_sources: int = Field(default=3, ge=1, le=10)
    
class QAResponse(BaseModel):
    answer: str
    sources: List[SourceInfo]
    confidence: float
    session_id: str
    reasoning: Optional[str] = None
```

#### 3.3 é›†æˆåˆ°ä¸»åº”ç”¨ (15åˆ†é’Ÿ)
- åœ¨ `app/main.py` ä¸­æ³¨å†Œè·¯ç”±
- æ·»åŠ ä¸­é—´ä»¶å’Œé”™è¯¯å¤„ç†
- é…ç½®CORSå’Œå®‰å…¨è®¾ç½®

### Phase 4: æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜ (45åˆ†é’Ÿ)

#### 4.1 åˆ›å»º `app/utils/cache_manager.py` (30åˆ†é’Ÿ)
**ç¼“å­˜ç­–ç•¥ï¼š**
- é—®é¢˜Embeddingç¼“å­˜
- æ–‡æ¡£å—ç¼“å­˜
- ç­”æ¡ˆç»“æœç¼“å­˜
- å¯¹è¯å†å²ç¼“å­˜

**å…³é”®ä¼˜åŒ–ï¼š**
- LRUç¼“å­˜ç­–ç•¥
- è¿‡æœŸæ—¶é—´ç®¡ç†
- å†…å­˜ä½¿ç”¨ç›‘æ§
- ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡

```python
class CacheManager:
    def __init__(self):
        self.embedding_cache = TTLCache(maxsize=1000, ttl=3600)
        self.answer_cache = TTLCache(maxsize=500, ttl=1800)
        self.chunk_cache = TTLCache(maxsize=2000, ttl=7200)
    
    def get_question_embedding(self, question):
        """è·å–é—®é¢˜embeddingï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        
    def cache_answer(self, question_hash, answer_data):
        """ç¼“å­˜ç­”æ¡ˆ"""
        
    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
```

#### 4.2 æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ– (15åˆ†é’Ÿ)
- å“åº”æ—¶é—´ç›‘æ§
- èµ„æºä½¿ç”¨ç»Ÿè®¡
- ç“¶é¢ˆè¯†åˆ«å’Œä¼˜åŒ–
- æ€§èƒ½æŒ‡æ ‡è®°å½•

### Phase 5: é”™è¯¯å¤„ç†å’Œé™çº§ (30åˆ†é’Ÿ)

#### 5.1 é”™è¯¯å¤„ç†ç­–ç•¥
**å¼‚å¸¸ç±»å‹ï¼š**
- AIæœåŠ¡ä¸å¯ç”¨
- å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥
- Tokenè¶…é™
- ç½‘ç»œè¶…æ—¶

**é™çº§ç­–ç•¥ï¼š**
- ä½¿ç”¨ç¼“å­˜ç­”æ¡ˆ
- è¿”å›ç›¸å…³æ–‡æ¡£å—
- æä¾›æœç´¢å»ºè®®
- å‹å¥½é”™è¯¯æç¤º

#### 5.2 ç†”æ–­å™¨æ¨¡å¼
```python
class AIServiceCircuitBreaker:
    def __init__(self):
        self.failure_threshold = 5
        self.recovery_timeout = 60
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    def call_ai_service(self, func, *args, **kwargs):
        """å¸¦ç†”æ–­å™¨çš„AIæœåŠ¡è°ƒç”¨"""
```

---

## ğŸ¯ è´¨é‡ä¿è¯è®¡åˆ’

### 1. å•å…ƒæµ‹è¯• (30åˆ†é’Ÿ)
- RAGæœåŠ¡æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
- å¯¹è¯ç®¡ç†åŠŸèƒ½æµ‹è¯•
- APIæ¥å£æµ‹è¯•
- ç¼“å­˜åŠŸèƒ½æµ‹è¯•

### 2. é›†æˆæµ‹è¯• (20åˆ†é’Ÿ)
- ç«¯åˆ°ç«¯é—®ç­”æµç¨‹æµ‹è¯•
- å¤šè½®å¯¹è¯æµ‹è¯•
- é”™è¯¯å¤„ç†æµ‹è¯•
- æ€§èƒ½å‹åŠ›æµ‹è¯•

### 3. ç”¨æˆ·ä½“éªŒæµ‹è¯• (10åˆ†é’Ÿ)
- é—®ç­”å‡†ç¡®æ€§éªŒè¯
- å“åº”é€Ÿåº¦æµ‹è¯•
- ç•Œé¢å‹å¥½æ€§æ£€æŸ¥

---

## ğŸš€ éƒ¨ç½²å’Œç›‘æ§

### 1. é…ç½®ç®¡ç†
```python
# config/rag_config.py
RAG_CONFIG = {
    "max_chunk_size": 1000,
    "overlap_size": 200,
    "top_k_retrieval": 5,
    "max_context_tokens": 3000,
    "conversation_max_turns": 10,
    "cache_ttl": 3600,
    "ai_timeout": 30,
    "retry_attempts": 3
}
```

### 2. æ—¥å¿—å’Œç›‘æ§
- é—®ç­”è¯·æ±‚æ—¥å¿—
- æ€§èƒ½æŒ‡æ ‡ç›‘æ§
- é”™è¯¯ç‡ç»Ÿè®¡
- ç”¨æˆ·è¡Œä¸ºåˆ†æ

### 3. A/Bæµ‹è¯•æ¡†æ¶
- ä¸åŒRAGç­–ç•¥å¯¹æ¯”
- æç¤ºè¯æ¨¡æ¿ä¼˜åŒ–
- ç¼“å­˜ç­–ç•¥éªŒè¯

---

## ğŸ“Š é¢„æœŸæ€§èƒ½æŒ‡æ ‡

### 1. å“åº”æ€§èƒ½
- å¹³å‡å“åº”æ—¶é—´: <3ç§’
- 95%å“åº”æ—¶é—´: <5ç§’
- ç¼“å­˜å‘½ä¸­ç‡: >70%
- å¹¶å‘å¤„ç†èƒ½åŠ›: 100 QPS

### 2. è´¨é‡æŒ‡æ ‡
- ç­”æ¡ˆå‡†ç¡®ç‡: >85%
- å¼•ç”¨å‡†ç¡®æ€§: >90%
- ç”¨æˆ·æ»¡æ„åº¦: >4.0/5.0
- å¯¹è¯è¿è´¯æ€§: >80%

### 3. èµ„æºä½¿ç”¨
- å†…å­˜ä½¿ç”¨: <2GB
- CPUä½¿ç”¨ç‡: <70%
- å­˜å‚¨å¢é•¿: <10MB/å¤©
- APIè°ƒç”¨æˆæœ¬ä¼˜åŒ–

---

## ğŸ”„ è¿­ä»£ä¼˜åŒ–è®¡åˆ’

### çŸ­æœŸä¼˜åŒ– (1-2å‘¨)
1. é—®ç­”å‡†ç¡®æ€§è°ƒä¼˜
2. å“åº”é€Ÿåº¦ä¼˜åŒ–
3. ç”¨æˆ·ç•Œé¢æ”¹è¿›
4. é”™è¯¯å¤„ç†å®Œå–„

### ä¸­æœŸä¼˜åŒ– (1ä¸ªæœˆ)
1. ä¸ªæ€§åŒ–é—®é¢˜æ¨è
2. å¤šæ¨¡æ€æ”¯æŒ(å›¾è¡¨ç†è§£)
3. æ‰¹é‡å¤„ç†èƒ½åŠ›
4. é«˜çº§åˆ†æåŠŸèƒ½

### é•¿æœŸä¼˜åŒ– (3ä¸ªæœˆ)
1. çŸ¥è¯†å›¾è°±é›†æˆ
2. å¤šè¯­è¨€æ”¯æŒ
3. å®æ—¶å­¦ä¹ èƒ½åŠ›
4. æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ

---

## ğŸ’¡ åˆ›æ–°ç‰¹æ€§

### 1. æ™ºèƒ½å¼•ç”¨éªŒè¯
- è‡ªåŠ¨éªŒè¯å¼•ç”¨å‡†ç¡®æ€§
- æ ‡æ³¨å¼•ç”¨å¯ä¿¡åº¦
- æä¾›åŸæ–‡å®šä½

### 2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¯¹è¯
- ç†è§£å¯¹è¯ä¸»é¢˜å˜åŒ–
- ä¿æŒè¯­ä¹‰è¿è´¯æ€§
- æ™ºèƒ½è¯é¢˜åˆ‡æ¢

### 3. è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥
- æ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´æ£€ç´¢ç­–ç•¥
- åŠ¨æ€è°ƒæ•´top-kå‚æ•°
- å¤šç­–ç•¥ç»“æœèåˆ

### 4. ç­”æ¡ˆè´¨é‡è¯„ä¼°
- å¤šç»´åº¦è´¨é‡æ‰“åˆ†
- ä¸ç¡®å®šæ€§é‡åŒ–
- æ”¹è¿›å»ºè®®æä¾›

è¿™ä¸ªè¯¦ç»†è®¡åˆ’ç¡®ä¿äº†RAGé—®ç­”ç³»ç»Ÿçš„é«˜è´¨é‡å®ç°ï¼ŒåŒæ—¶è€ƒè™‘äº†æ€§èƒ½ä¼˜åŒ–ã€ç”¨æˆ·ä½“éªŒå’Œå¯ç»´æŠ¤æ€§ã€‚ 