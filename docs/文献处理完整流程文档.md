# 文献处理系统完整后端流程技术文档

## 概述
本文档详细描述了从用户上传文献到AI聊天界面生成回答的完整后端处理流程，包括文件处理、向量生成、存储和智能问答的每个步骤。

## 整体架构图
```
用户上传文献 → 文件验证与保存 → 数据库记录 → 异步向量生成 → 向量存储
                                                                    ↓
用户AI提问 ← AI答案生成 ← 提示词构建 ← 相关文档检索 ← 问题向量化 ← 向量库
```

## 第一阶段：文献上传处理流程

### 1.1 入口点：私人文献上传API
**文件位置**: `app/main.py` 第344-430行  
**函数名**: `upload_private_literature()`

**处理步骤**:
1. **接收上传请求**: 接收`UploadFile`、可选标题、数据库会话、当前用户信息
2. **初始化操作信息**: 记录文件名、用户ID、文件大小等基础信息

### 1.2 文件验证
**文件位置**: `app/utils/file_operations.py`  
**函数名**: `validate_upload_file()`

**验证内容**:
- 文件类型检查（PDF、Word等学术文档）
- 文件大小限制（通常50MB以内）
- 文件完整性验证

### 1.3 文件信息提取
**文件位置**: `app/utils/file_operations.py`  
**函数名**: `get_file_info()`

**提取信息**:
- 文件大小（字节）
- 文件类型
- 创建时间
- 编码格式

### 1.4 文件路径生成与保存
**文件位置**: `app/utils/file_operations.py`  
**函数名**: `generate_file_path()`, `save_uploaded_file()`

**处理逻辑**:
- 为私人文献生成唯一存储路径：`private_{user_id}/{filename}`
- 创建目录结构（如不存在）
- 安全保存文件到磁盘

### 1.5 元数据提取
**文件位置**: `app/utils/metadata_extractor.py`  
**函数名**: `extract_metadata_from_file()`

**提取内容**:
- PDF元数据（标题、作者、创建时间）
- Word文档属性
- 如用户未指定标题，尝试从元数据获取

### 1.6 数据库记录创建
**文件位置**: `app/main.py` 第390-410行  
**模型**: `Literature`

**关键字段**:
- `research_group_id`: 设为`None`（表示私人文献）
- `title`: 最终确定的标题
- `filename`: 原始文件名
- `file_path`: 相对存储路径
- `uploaded_by`: 当前用户ID
- `status`: 默认为`active`

## 第二阶段：异步向量生成流程

### 2.1 异步任务启动
**文件位置**: `app/main.py` 第412-418行  
**调用链**: `async_processor.process_literature_async(literature.id)`

**任务创建**:
- 生成唯一任务ID
- 创建后台处理线程
- 初始化任务状态追踪

### 2.2 异步处理器工作流程
**文件位置**: `app/utils/async_processor.py` 第77-200行  
**函数名**: `_process_literature_worker()`

**详细步骤**:

#### 2.2.1 获取文献信息（进度10%）
- 从数据库查询文献记录
- 验证文献状态和存在性
- 构建完整文件路径

#### 2.2.2 文本提取（进度20%）
**函数名**: `extract_text_from_file()`
- PDF文本提取（使用PyMuPDF或PyPDF2）
- Word文档处理（使用python-docx）
- 文本清理和格式化

#### 2.2.3 文本分块（进度40%）
**函数名**: `split_text_into_chunks()`
- 按语义边界分割长文本
- 每块控制在适当长度（通常500-1000字符）
- 保持上下文连贯性

#### 2.2.4 准备向量数据（进度50%）
**函数名**: `prepare_chunks_for_embedding()`
- 为每个文本块添加元数据
- 包含：文献ID、课题组ID、标题、块索引

#### 2.2.5 生成向量嵌入（进度60%）
**文件位置**: `app/utils/embedding_service.py`  
**函数名**: `batch_generate_embeddings()`
- 批量调用AI模型生成向量
- 通常使用text-embedding-ada-002或类似模型
- 每个文本块生成1536维向量

### 2.3 向量存储
**文件位置**: `app/utils/vector_store.py` 第170-200行  
**函数名**: `store_document_chunks()`

**存储步骤**:
1. **清理旧向量**: 删除该文献的已有向量
2. **批量插入**: 将新向量存储到ChromaDB
3. **元数据关联**: 保存文本内容、相似度阈值等

## 第三阶段：AI问答处理流程

### 3.1 问答API入口
**文件位置**: `app/routers/ai_chat.py` 第85-150行  
**函数名**: `ask_question()`

**接收参数**:
- `question`: 用户问题
- `literature_id`: 目标文献ID
- `session_id`: 会话ID（可选）
- `max_sources`: 最大引用来源数
- `include_history`: 是否包含历史对话

### 3.2 权限验证
**函数名**: `_check_literature_access()`

**验证逻辑**:
- 检查文献是否存在
- 验证用户访问权限
- 私人文献：仅上传者可访问
- 课题组文献：组成员可访问

### 3.3 会话管理
**文件位置**: `app/utils/conversation_manager.py`  
**函数名**: `get_or_create_session()`

**处理逻辑**:
- 检查是否存在活跃会话
- 创建新会话（如需要）
- 更新会话活跃时间

### 3.4 RAG核心处理
**文件位置**: `app/utils/rag_service.py` 第60-180行  
**函数名**: `process_question()`

#### 3.4.1 问题预处理（并行处理）
**函数名**: `_preprocess_question()`, `_generate_question_embedding()`
- 清理用户输入
- 生成问题的向量嵌入
- 处理对话历史上下文

#### 3.4.2 相关文档检索
**函数名**: `_retrieve_relevant_chunks()`
- 使用问题向量在ChromaDB中搜索
- 计算余弦相似度
- 返回最相关的文档块（通常top-5）

#### 3.4.3 缓存检查
**文件位置**: `app/utils/cache_manager.py`  
**函数名**: `get_answer()`
- 检查是否有相似问题的缓存答案
- 基于问题hash和文献ID匹配

#### 3.4.4 提示词构建
**文件位置**: `app/utils/prompt_builder.py` 第35-80行  
**函数名**: `build_qa_prompt()`

**构建内容**:
- 系统角色定义
- 相关文献内容
- 对话历史（如有）
- 用户问题
- 输出格式要求

#### 3.4.5 AI模型调用
**函数名**: `_generate_ai_answer()`
- 调用Google Gemini或类似AI模型
- 传入完整提示词
- 获取结构化回答

#### 3.4.6 答案后处理
**文件位置**: `app/utils/answer_processor.py`  
**函数名**: `process_answer()`

**处理内容**:
- 解析AI回答的结构化内容
- 提取引用来源信息
- 计算置信度分数
- 验证答案质量

### 3.5 响应构建与返回
**处理步骤**:
1. **构建引用来源**: 整理相关文档块信息
2. **记录对话轮次**: 保存到数据库
3. **缓存答案**: 存储以备后续使用
4. **返回结构化响应**: 包含答案、来源、置信度等

## 关键数据流

### 向量数据结构
```python
{
    "literature_id": "文献唯一标识",
    "group_id": "课题组ID或None(私人文献)",
    "chunk_index": "文本块索引",
    "text": "文本内容",
    "embedding": [1536维向量],
    "metadata": {
        "title": "文献标题",
        "chunk_length": "文本长度",
        "created_at": "创建时间"
    }
}
```

### AI问答响应结构
```python
{
    "answer": "AI生成的回答",
    "sources": [
        {
            "id": "来源ID",
            "text": "引用文本",
            "similarity": 0.85,
            "description": "来源描述",
            "chunk_index": 1
        }
    ],
    "confidence": 0.92,
    "session_id": "会话ID",
    "turn_id": "轮次ID",
    "metadata": {
        "processing_time": 2.5,
        "chunks_retrieved": 5,
        "prompt_tokens": 1200
    }
}
```

## 错误处理机制

### 文献上传阶段
- 文件验证失败：返回具体错误信息
- 存储失败：清理部分保存的文件
- 数据库错误：回滚操作并清理文件

### 向量生成阶段
- 文本提取失败：记录错误，标记文献需要重新处理
- 向量生成失败：重试机制，最终失败则记录日志
- 存储失败：清理部分数据，保持一致性

### AI问答阶段
- 权限验证失败：返回403错误
- 检索失败：返回"无相关内容"提示
- AI模型错误：降级到缓存答案或错误提示

## 性能优化策略

1. **异步处理**: 文献上传后立即返回，后台处理向量
2. **批量向量生成**: 减少AI模型调用次数
3. **答案缓存**: 相似问题复用之前的答案
4. **并行处理**: 问题向量化与历史处理并行
5. **分块检索**: 只检索最相关的文档块

## 监控与日志

### 关键监控指标
- 文献上传成功率
- 向量生成处理时间
- AI问答响应时间
- 缓存命中率

### 日志记录点
- 每个主要处理步骤的开始和结束
- 错误详细信息和堆栈跟踪
- 性能指标（处理时间、token使用量）
- 用户操作审计日志

## 配置参数

```python
# 文件上传
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
ALLOWED_EXTENSIONS = ['.pdf', '.docx', '.doc']

# 向量处理
CHUNK_SIZE = 1000  # 文本块大小
CHUNK_OVERLAP = 200  # 块重叠
EMBEDDING_DIMENSION = 1536  # 向量维度

# AI问答
MAX_SOURCES = 5  # 最大引用来源
MAX_CONVERSATION_TURNS = 10  # 最大对话轮数
CACHE_EXPIRY = 3600  # 缓存过期时间（秒）
```

---
**文档生成时间**: 2024年12月
**版本**: 1.0
**维护者**: AI文献系统开发团队 