# ç¼“å­˜ç®¡ç†å™¨è¯¦ç»†å®ç°è§„åˆ’

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. æ ¸å¿ƒç±»è®¾è®¡

```python
# app/utils/cache_manager.py

from typing import Any, Optional, Dict, List, Tuple
from datetime import datetime, timedelta
import hashlib
import json
import logging
from abc import ABC, abstractmethod
from cachetools import TTLCache, LRUCache
import threading
from dataclasses import dataclass

@dataclass
class CacheItem:
    """ç¼“å­˜é¡¹æ•°æ®ç»“æ„"""
    key: str
    value: Any
    created_at: datetime
    accessed_at: datetime
    access_count: int
    size_bytes: int
    ttl: Optional[int] = None
    tags: List[str] = None

class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡ç±»"""
    def __init__(self):
        self.hits = 0
        self.misses = 0
        self.sets = 0
        self.deletes = 0
        self.evictions = 0
        self.start_time = datetime.now()
    
    def hit_rate(self) -> float:
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0

class BaseCacheBackend(ABC):
    """ç¼“å­˜åç«¯æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def get(self, key: str) -> Optional[Any]:
        pass
    
    @abstractmethod
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        pass
    
    @abstractmethod
    def delete(self, key: str) -> bool:
        pass
    
    @abstractmethod
    def clear(self) -> bool:
        pass
    
    @abstractmethod
    def size(self) -> int:
        pass

class MemoryCacheBackend(BaseCacheBackend):
    """å†…å­˜ç¼“å­˜åç«¯"""
    
    def __init__(self, maxsize: int = 1000, ttl: int = 3600):
        self.cache = TTLCache(maxsize=maxsize, ttl=ttl)
        self.lock = threading.RLock()
    
    def get(self, key: str) -> Optional[Any]:
        with self.lock:
            return self.cache.get(key)
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        with self.lock:
            self.cache[key] = value
            return True
    
    def delete(self, key: str) -> bool:
        with self.lock:
            return self.cache.pop(key, None) is not None
    
    def clear(self) -> bool:
        with self.lock:
            self.cache.clear()
            return True
    
    def size(self) -> int:
        with self.lock:
            return len(self.cache)

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.stats = CacheStats()
        
        # åˆå§‹åŒ–ä¸åŒç±»å‹çš„ç¼“å­˜
        self.embedding_cache = MemoryCacheBackend(
            maxsize=Config.RAG_CACHE_EMBEDDING_MAX_SIZE,
            ttl=Config.RAG_CACHE_TTL
        )
        
        self.answer_cache = MemoryCacheBackend(
            maxsize=Config.RAG_CACHE_ANSWER_MAX_SIZE,
            ttl=Config.RAG_CACHE_TTL // 2
        )
        
        self.chunk_cache = MemoryCacheBackend(
            maxsize=Config.RAG_CACHE_CHUNK_MAX_SIZE,
            ttl=Config.RAG_CACHE_TTL * 2
        )
        
        self.logger.info("ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
```

### 2. ç¼“å­˜é”®ç”Ÿæˆç­–ç•¥

```python
class CacheKeyGenerator:
    """ç¼“å­˜é”®ç”Ÿæˆå™¨"""
    
    @staticmethod
    def embedding_key(text: str, model: str = "default") -> str:
        """ç”Ÿæˆembeddingç¼“å­˜é”®"""
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()[:12]
        return f"emb:{model}:{text_hash}"
    
    @staticmethod
    def answer_key(question: str, literature_id: str, context_hash: str) -> str:
        """ç”Ÿæˆç­”æ¡ˆç¼“å­˜é”®"""
        question_hash = hashlib.md5(question.encode('utf-8')).hexdigest()[:8]
        return f"ans:{literature_id}:{question_hash}:{context_hash[:8]}"
    
    @staticmethod
    def chunk_key(literature_id: str, chunk_index: int) -> str:
        """ç”Ÿæˆæ–‡æ¡£å—ç¼“å­˜é”®"""
        return f"chunk:{literature_id}:{chunk_index}"
    
    @staticmethod
    def context_hash(chunks: List[Dict]) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡å“ˆå¸Œ"""
        context_str = json.dumps([c.get('text', '')[:100] for c in chunks], sort_keys=True)
        return hashlib.md5(context_str.encode('utf-8')).hexdigest()[:16]
```

## ğŸ“… åˆ†é˜¶æ®µå®æ–½è®¡åˆ’

### Phase 1: åŸºç¡€å†…å­˜ç¼“å­˜ (3-4å¤©)

#### Day 1: æ ¸å¿ƒæ¶æ„å®ç°
**ä»»åŠ¡æ¸…å•:**
- [ ] åˆ›å»º `app/utils/cache_manager.py` æ–‡ä»¶
- [ ] å®ç° `BaseCacheBackend` æŠ½è±¡ç±»
- [ ] å®ç° `MemoryCacheBackend` å†…å­˜ç¼“å­˜
- [ ] å®ç° `CacheKeyGenerator` é”®ç”Ÿæˆå™¨
- [ ] å®ç° `CacheStats` ç»Ÿè®¡ç±»

**å…³é”®ä»£ç :**
```python
# åŸºç¡€ç¼“å­˜ç®¡ç†å™¨å®ç°
class CacheManager:
    def get_embedding(self, text: str) -> Optional[List[float]]:
        """è·å–embeddingï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        key = CacheKeyGenerator.embedding_key(text)
        cached = self.embedding_cache.get(key)
        
        if cached is not None:
            self.stats.hits += 1
            self.logger.debug(f"Embeddingç¼“å­˜å‘½ä¸­: {key}")
            return cached
        
        self.stats.misses += 1
        return None
    
    def set_embedding(self, text: str, embedding: List[float]) -> bool:
        """è®¾ç½®embeddingç¼“å­˜"""
        key = CacheKeyGenerator.embedding_key(text)
        success = self.embedding_cache.set(key, embedding)
        
        if success:
            self.stats.sets += 1
            self.logger.debug(f"Embeddingå·²ç¼“å­˜: {key}")
        
        return success
```

#### Day 2: é›†æˆåˆ°ç°æœ‰æœåŠ¡
**ä»»åŠ¡æ¸…å•:**
- [ ] ä¿®æ”¹ `embedding_service.py` é›†æˆç¼“å­˜
- [ ] ä¿®æ”¹ `rag_service.py` é›†æˆç­”æ¡ˆç¼“å­˜
- [ ] ä¿®æ”¹ `vector_store.py` é›†æˆæ–‡æ¡£å—ç¼“å­˜
- [ ] æ·»åŠ ç¼“å­˜é…ç½®å‚æ•°

**é›†æˆç¤ºä¾‹:**
```python
# app/utils/embedding_service.py ä¿®æ”¹
class EmbeddingService:
    def __init__(self):
        # ... ç°æœ‰åˆå§‹åŒ–ä»£ç 
        self.cache_manager = cache_manager
    
    def generate_embedding(self, text: str) -> Optional[List[float]]:
        # 1. å…ˆæ£€æŸ¥ç¼“å­˜
        cached_embedding = self.cache_manager.get_embedding(text)
        if cached_embedding is not None:
            return cached_embedding
        
        # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œç”Ÿæˆæ–°çš„embedding
        embedding = self._generate_google_embedding(text)
        
        # 3. å­˜å…¥ç¼“å­˜
        if embedding:
            self.cache_manager.set_embedding(text, embedding)
        
        return embedding
```

#### Day 3: ç­”æ¡ˆç¼“å­˜å®ç°
**ä»»åŠ¡æ¸…å•:**
- [ ] å®ç°ç­”æ¡ˆç¼“å­˜é€»è¾‘
- [ ] å¤„ç†ä¸Šä¸‹æ–‡ç›¸å…³çš„ç¼“å­˜ç­–ç•¥
- [ ] å®ç°ç¼“å­˜å¤±æ•ˆæœºåˆ¶

**å…³é”®ä»£ç :**
```python
class CacheManager:
    def get_answer(self, question: str, literature_id: str, 
                   context_chunks: List[Dict]) -> Optional[Dict]:
        """è·å–ç­”æ¡ˆç¼“å­˜"""
        context_hash = CacheKeyGenerator.context_hash(context_chunks)
        key = CacheKeyGenerator.answer_key(question, literature_id, context_hash)
        
        cached = self.answer_cache.get(key)
        if cached is not None:
            self.stats.hits += 1
            # æ›´æ–°æ—¶é—´æˆ³
            cached['metadata']['cache_hit'] = True
            cached['metadata']['retrieved_at'] = datetime.now().isoformat()
            return cached
        
        self.stats.misses += 1
        return None
    
    def set_answer(self, question: str, literature_id: str, 
                   context_chunks: List[Dict], answer_data: Dict) -> bool:
        """è®¾ç½®ç­”æ¡ˆç¼“å­˜"""
        context_hash = CacheKeyGenerator.context_hash(context_chunks)
        key = CacheKeyGenerator.answer_key(question, literature_id, context_hash)
        
        # æ·»åŠ ç¼“å­˜å…ƒæ•°æ®
        cached_answer = answer_data.copy()
        cached_answer['metadata']['cached_at'] = datetime.now().isoformat()
        cached_answer['metadata']['context_hash'] = context_hash
        
        return self.answer_cache.set(key, cached_answer)
```

#### Day 4: ç›‘æ§å’Œè°ƒè¯•
**ä»»åŠ¡æ¸…å•:**
- [ ] å®ç°ç¼“å­˜ç»Ÿè®¡æ¥å£
- [ ] æ·»åŠ ç¼“å­˜ç›‘æ§æ—¥å¿—
- [ ] åˆ›å»ºç¼“å­˜è°ƒè¯•å·¥å…·
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•

### Phase 2: é«˜çº§ç¼“å­˜åŠŸèƒ½ (2-3å¤©)

#### Day 5: TTLå’Œæ·˜æ±°ç­–ç•¥
**ä»»åŠ¡æ¸…å•:**
- [ ] å®ç°çµæ´»çš„TTLè®¾ç½®
- [ ] å®ç°LRU + TTLæ··åˆæ·˜æ±°
- [ ] å®ç°åŸºäºæ ‡ç­¾çš„æ‰¹é‡æ¸…ç†
- [ ] å®ç°ç¼“å­˜é¢„çƒ­æœºåˆ¶

**é«˜çº§æ·˜æ±°ç­–ç•¥:**
```python
class SmartEvictionStrategy:
    """æ™ºèƒ½æ·˜æ±°ç­–ç•¥"""
    
    def should_evict(self, item: CacheItem) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ·˜æ±°ç¼“å­˜é¡¹"""
        now = datetime.now()
        
        # 1. TTLæ£€æŸ¥
        if item.ttl and (now - item.created_at).seconds > item.ttl:
            return True
        
        # 2. è®¿é—®é¢‘ç‡æ£€æŸ¥
        item_age = (now - item.created_at).seconds
        if item_age > 3600 and item.access_count < 2:  # 1å°æ—¶å†…è®¿é—®å°‘äº2æ¬¡
            return True
        
        # 3. æœ€åè®¿é—®æ—¶é—´æ£€æŸ¥
        if (now - item.accessed_at).seconds > 1800:  # 30åˆ†é’Ÿæœªè®¿é—®
            return True
        
        return False

class CacheWarmer:
    """ç¼“å­˜é¢„çƒ­å™¨"""
    
    def __init__(self, cache_manager: CacheManager):
        self.cache_manager = cache_manager
        self.logger = logging.getLogger(__name__)
    
    async def warm_frequently_used_embeddings(self):
        """é¢„çƒ­å¸¸ç”¨é—®é¢˜çš„embeddings"""
        common_questions = [
            "è¿™ç¯‡æ–‡çŒ®çš„ä¸»è¦ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ",
            "æ–‡çŒ®ä¸­çš„å®éªŒæ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ",
            "è¿™é¡¹ç ”ç©¶æœ‰ä»€ä¹ˆåˆ›æ–°ç‚¹ï¼Ÿ"
        ]
        
        for question in common_questions:
            if not self.cache_manager.get_embedding(question):
                # ç”Ÿæˆå¹¶ç¼“å­˜embedding
                embedding = await embedding_service.generate_embedding(question)
                if embedding:
                    self.cache_manager.set_embedding(question, embedding)
                    self.logger.info(f"é¢„çƒ­embedding: {question[:30]}...")
```

#### Day 6-7: æŒä¹…åŒ–ç¼“å­˜
**ä»»åŠ¡æ¸…å•:**
- [ ] å®ç°SQLiteæŒä¹…åŒ–ç¼“å­˜
- [ ] å®ç°ç¼“å­˜æ•°æ®çš„åºåˆ—åŒ–/ååºåˆ—åŒ–
- [ ] å®ç°å¤šå±‚ç¼“å­˜åè°ƒæœºåˆ¶
- [ ] å®ç°ç¼“å­˜æ•°æ®æ¢å¤

### Phase 3: æ€§èƒ½ä¼˜åŒ– (1-2å¤©)

#### Day 8: æ€§èƒ½è°ƒä¼˜
**ä»»åŠ¡æ¸…å•:**
- [ ] å®ç°å¼‚æ­¥ç¼“å­˜æ“ä½œ
- [ ] ä¼˜åŒ–ç¼“å­˜é”®ç”Ÿæˆç®—æ³•
- [ ] å®ç°æ‰¹é‡ç¼“å­˜æ“ä½œ
- [ ] å†…å­˜ä½¿ç”¨ä¼˜åŒ–

**å¼‚æ­¥ç¼“å­˜å®ç°:**
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncCacheManager:
    """å¼‚æ­¥ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.sync_manager = CacheManager()
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def get_embedding_async(self, text: str) -> Optional[List[float]]:
        """å¼‚æ­¥è·å–embedding"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor, 
            self.sync_manager.get_embedding, 
            text
        )
    
    async def set_embedding_async(self, text: str, embedding: List[float]) -> bool:
        """å¼‚æ­¥è®¾ç½®embedding"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self.sync_manager.set_embedding,
            text, embedding
        )
```

## ğŸ”§ é…ç½®å’Œé›†æˆ

### 1. é…ç½®å‚æ•°æ‰©å±•

```python
# app/config.py æ·»åŠ 
class Config:
    # ... ç°æœ‰é…ç½®
    
    # ===== ç¼“å­˜é…ç½® =====
    
    # åŸºç¡€ç¼“å­˜è®¾ç½®
    CACHE_ENABLED: bool = True
    CACHE_DEFAULT_TTL: int = int(os.getenv("CACHE_DEFAULT_TTL", "3600"))  # 1å°æ—¶
    
    # å†…å­˜ç¼“å­˜é…ç½®
    CACHE_EMBEDDING_SIZE: int = int(os.getenv("CACHE_EMBEDDING_SIZE", "1000"))
    CACHE_EMBEDDING_TTL: int = int(os.getenv("CACHE_EMBEDDING_TTL", "7200"))  # 2å°æ—¶
    
    CACHE_ANSWER_SIZE: int = int(os.getenv("CACHE_ANSWER_SIZE", "500"))
    CACHE_ANSWER_TTL: int = int(os.getenv("CACHE_ANSWER_TTL", "1800"))  # 30åˆ†é’Ÿ
    
    CACHE_CHUNK_SIZE: int = int(os.getenv("CACHE_CHUNK_SIZE", "2000"))
    CACHE_CHUNK_TTL: int = int(os.getenv("CACHE_CHUNK_TTL", "14400"))  # 4å°æ—¶
    
    # ç¼“å­˜è¡Œä¸ºé…ç½®
    CACHE_PRELOAD_ON_STARTUP: bool = os.getenv("CACHE_PRELOAD_ON_STARTUP", "false").lower() == "true"
    CACHE_STATS_ENABLED: bool = os.getenv("CACHE_STATS_ENABLED", "true").lower() == "true"
    CACHE_CLEANUP_INTERVAL: int = int(os.getenv("CACHE_CLEANUP_INTERVAL", "300"))  # 5åˆ†é’Ÿ
    
    # æŒä¹…åŒ–ç¼“å­˜é…ç½®
    CACHE_PERSISTENT_ENABLED: bool = os.getenv("CACHE_PERSISTENT_ENABLED", "false").lower() == "true"
    CACHE_PERSISTENT_PATH: str = os.getenv("CACHE_PERSISTENT_PATH", "./cache_storage")
```

### 2. APIæ¥å£æ‰©å±•

```python
# app/routers/cache_admin.py
from fastapi import APIRouter, Depends, HTTPException
from app.utils.cache_manager import cache_manager

router = APIRouter(prefix="/admin/cache", tags=["ç¼“å­˜ç®¡ç†"])

@router.get("/stats")
async def get_cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    return {
        "embedding_cache": {
            "hits": cache_manager.stats.hits,
            "misses": cache_manager.stats.misses,
            "hit_rate": cache_manager.stats.hit_rate(),
            "size": cache_manager.embedding_cache.size()
        },
        "answer_cache": {
            "size": cache_manager.answer_cache.size()
        },
        "chunk_cache": {
            "size": cache_manager.chunk_cache.size()
        }
    }

@router.post("/clear")
async def clear_cache(cache_type: str = "all"):
    """æ¸…ç†ç¼“å­˜"""
    if cache_type == "all":
        cache_manager.clear_all()
    elif cache_type == "embedding":
        cache_manager.embedding_cache.clear()
    elif cache_type == "answer":
        cache_manager.answer_cache.clear()
    elif cache_type == "chunk":
        cache_manager.chunk_cache.clear()
    else:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ç¼“å­˜ç±»å‹")
    
    return {"message": f"ç¼“å­˜ {cache_type} å·²æ¸…ç†"}

@router.post("/warm")
async def warm_cache():
    """é¢„çƒ­ç¼“å­˜"""
    await cache_manager.warmer.warm_frequently_used_embeddings()
    return {"message": "ç¼“å­˜é¢„çƒ­å®Œæˆ"}
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•è®¡åˆ’

### 1. æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
# test/test_cache_performance.py
import time
import asyncio
import pytest
from app.utils.cache_manager import cache_manager

class TestCachePerformance:
    
    def test_embedding_cache_performance(self):
        """æµ‹è¯•embeddingç¼“å­˜æ€§èƒ½"""
        test_texts = [f"æµ‹è¯•æ–‡æœ¬ {i}" for i in range(100)]
        
        # æ— ç¼“å­˜æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        for text in test_texts:
            embedding_service.generate_embedding(text)
        no_cache_time = time.time() - start_time
        
        # æœ‰ç¼“å­˜æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        for text in test_texts:
            # ç¬¬äºŒæ¬¡è°ƒç”¨åº”è¯¥å‘½ä¸­ç¼“å­˜
            cache_manager.get_embedding(text)
        cache_time = time.time() - start_time
        
        improvement = (no_cache_time - cache_time) / no_cache_time * 100
        assert improvement > 90  # è‡³å°‘90%çš„æ€§èƒ½æå‡
        
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # å¤§é‡æ•°æ®å†™å…¥ç¼“å­˜
        for i in range(1000):
            cache_manager.set_embedding(f"test_{i}", [0.1] * 768)
        
        peak_memory = process.memory_info().rss
        memory_increase = (peak_memory - initial_memory) / 1024 / 1024  # MB
        
        assert memory_increase < 100  # å†…å­˜å¢é•¿ä¸è¶…è¿‡100MB
```

### 2. è´Ÿè½½æµ‹è¯•

```python
async def load_test_cache():
    """ç¼“å­˜è´Ÿè½½æµ‹è¯•"""
    import aiohttp
    
    async def worker(session, worker_id):
        for i in range(100):
            async with session.post("/ai/ask", json={
                "question": f"æµ‹è¯•é—®é¢˜ {worker_id}_{i}",
                "literature_id": "test_lit_id"
            }) as response:
                assert response.status == 200
    
    async with aiohttp.ClientSession() as session:
        tasks = [worker(session, i) for i in range(10)]
        await asyncio.gather(*tasks)
```

## ğŸš€ éƒ¨ç½²å’Œè¿ç»´

### 1. ç›‘æ§å’Œå‘Šè­¦

```python
class CacheHealthMonitor:
    """ç¼“å­˜å¥åº·ç›‘æ§"""
    
    def __init__(self, cache_manager: CacheManager):
        self.cache_manager = cache_manager
        self.logger = logging.getLogger(__name__)
    
    def check_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç¼“å­˜å¥åº·çŠ¶å†µ"""
        stats = self.cache_manager.stats
        
        # æ£€æŸ¥å‘½ä¸­ç‡
        hit_rate = stats.hit_rate()
        hit_rate_status = "healthy" if hit_rate > 0.7 else "warning" if hit_rate > 0.4 else "critical"
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        memory_usage = self._get_memory_usage()
        memory_status = "healthy" if memory_usage < 0.8 else "warning" if memory_usage < 0.9 else "critical"
        
        return {
            "overall_status": "healthy" if all(s == "healthy" for s in [hit_rate_status, memory_status]) else "degraded",
            "hit_rate": {
                "value": hit_rate,
                "status": hit_rate_status
            },
            "memory_usage": {
                "value": memory_usage,
                "status": memory_status
            },
            "cache_sizes": {
                "embedding": self.cache_manager.embedding_cache.size(),
                "answer": self.cache_manager.answer_cache.size(),
                "chunk": self.cache_manager.chunk_cache.size()
            }
        }
```

### 2. è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬

```bash
#!/bin/bash
# scripts/cache_maintenance.sh

# ç¼“å­˜ç»´æŠ¤è„šæœ¬
echo "å¼€å§‹ç¼“å­˜ç»´æŠ¤..."

# 1. æ£€æŸ¥ç¼“å­˜å¥åº·çŠ¶å†µ
curl -s http://localhost:8000/admin/cache/stats | jq .

# 2. æ¸…ç†è¿‡æœŸç¼“å­˜
if [ $(date +%H) -eq 2 ]; then  # å‡Œæ™¨2ç‚¹
    echo "æ‰§è¡Œç¼“å­˜æ¸…ç†..."
    curl -X POST http://localhost:8000/admin/cache/clear?cache_type=expired
fi

# 3. é¢„çƒ­ç¼“å­˜
if [ $(date +%H) -eq 6 ]; then  # æ—©ä¸Š6ç‚¹
    echo "æ‰§è¡Œç¼“å­˜é¢„çƒ­..."
    curl -X POST http://localhost:8000/admin/cache/warm
fi

echo "ç¼“å­˜ç»´æŠ¤å®Œæˆ"
```

## ğŸ“ˆ é¢„æœŸæ”¶ç›Šè¯„ä¼°

### 1. æ€§èƒ½æå‡é¢„æœŸ

| æ“ä½œç±»å‹ | æ— ç¼“å­˜å“åº”æ—¶é—´ | æœ‰ç¼“å­˜å“åº”æ—¶é—´ | æå‡å¹…åº¦ |
|---------|---------------|---------------|----------|
| Embeddingç”Ÿæˆ | 2-5ç§’ | 10-50ms | **95-99%** |
| ç›¸åŒé—®é¢˜å›ç­” | 8-15ç§’ | 100-500ms | **92-96%** |
| æ–‡æ¡£å—æ£€ç´¢ | 500ms-2s | 10-100ms | **80-95%** |

### 2. æˆæœ¬èŠ‚çº¦é¢„æœŸ

| æˆæœ¬é¡¹ | æœˆåº¦èŠ‚çº¦ | å¹´åº¦èŠ‚çº¦ |
|--------|----------|----------|
| AI APIè°ƒç”¨è´¹ç”¨ | 60-80% | $1000-5000 |
| æœåŠ¡å™¨è®¡ç®—èµ„æº | 30-50% | $500-2000 |
| ç”¨æˆ·ç­‰å¾…æ—¶é—´æˆæœ¬ | æ˜¾è‘—æå‡ | ç”¨æˆ·æ»¡æ„åº¦+++ |

### 3. è¿ç»´æ•ˆç›Š

- **ç³»ç»Ÿå“åº”èƒ½åŠ›**: æå‡3-5å€
- **å¹¶å‘å¤„ç†èƒ½åŠ›**: æå‡2-3å€  
- **ç³»ç»Ÿç¨³å®šæ€§**: å‡å°‘APIä¾èµ–ï¼Œæå‡é²æ£’æ€§
- **ç”¨æˆ·ä½“éªŒ**: æ˜¾è‘—æ”¹å–„ï¼Œç‰¹åˆ«æ˜¯é‡å¤æŸ¥è¯¢åœºæ™¯

è¿™ä¸ªå®ç°è§„åˆ’æä¾›äº†å®Œæ•´çš„æŠ€æœ¯è·¯çº¿å›¾ï¼Œç¡®ä¿ç¼“å­˜ç®¡ç†å™¨èƒ½å¤Ÿæœ‰æ•ˆæå‡ç³»ç»Ÿæ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚ 