#!/usr/bin/env python3
"""
å‘é‡æ•°æ®åº“åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ChromaDBé›†æˆã€embeddingç”Ÿæˆã€å‘é‡å­˜å‚¨å’Œæ£€ç´¢ç­‰åŠŸèƒ½
"""

import os
import sys
import tempfile
import time
import requests
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.utils.vector_store import VectorStore, vector_store
from app.utils.embedding_service import EmbeddingService, embedding_service
from app.utils.text_processor import split_text_into_chunks, prepare_chunks_for_embedding
from app.config import settings

# APIåŸºç¡€URL
BASE_URL = "http://localhost:8000"

class VectorDatabaseTester:
    def __init__(self):
        self.token = None
        self.user_id = None
        self.group_id = None
        self.literature_id = None
        self.vector_store = VectorStore()
        self.embedding_service = EmbeddingService()
    
    def login(self):
        """ç™»å½•è·å–token"""
        print("ğŸ” ç”¨æˆ·ç™»å½•...")
        
        login_data = {
            "username": "testuser",
            "password": "testpass123"
        }
        
        response = requests.post(f"{BASE_URL}/login", data=login_data)
        
        if response.status_code == 200:
            result = response.json()
            self.token = result["access_token"]
            import jwt
            payload = jwt.decode(result["access_token"], options={"verify_signature": False})
            self.user_id = payload.get("sub")
            print(f"   âœ… ç™»å½•æˆåŠŸ: {self.user_id}")
            return True
        else:
            print(f"   âŒ ç™»å½•å¤±è´¥: {response.text}")
            return False
    
    def get_headers(self):
        """è·å–è®¤è¯å¤´"""
        return {"Authorization": f"Bearer {self.token}"}
    
    def get_user_groups(self):
        """è·å–ç”¨æˆ·ç ”ç©¶ç»„"""
        print("\nğŸ“‹ è·å–ç”¨æˆ·ç ”ç©¶ç»„...")
        
        response = requests.get(f"{BASE_URL}/user/groups", headers=self.get_headers())
        
        if response.status_code == 200:
            groups = response.json()["groups"]
            if groups:
                self.group_id = groups[0]["id"]
                print(f"   âœ… æ‰¾åˆ°ç ”ç©¶ç»„: {groups[0]['name']} ({self.group_id})")
                return True
            else:
                print("   âŒ ç”¨æˆ·æ²¡æœ‰åŠ å…¥ä»»ä½•ç ”ç©¶ç»„")
                return False
        else:
            print(f"   âŒ è·å–ç ”ç©¶ç»„å¤±è´¥: {response.text}")
            return False
    
    def test_configuration(self):
        """æµ‹è¯•é…ç½®ä¿¡æ¯"""
        print("\nâš™ï¸  æµ‹è¯•é…ç½®ä¿¡æ¯...")
        
        print(f"   AIæä¾›å•†: {settings.get_ai_provider()}")
        print(f"   å‘é‡æ•°æ®åº“è·¯å¾„: {settings.VECTOR_DB_PATH}")
        print(f"   é›†åˆå‰ç¼€: {settings.VECTOR_DB_COLLECTION_PREFIX}")
        
        ai_valid, ai_message = settings.validate_ai_config()
        print(f"   AIé…ç½®: {'âœ…' if ai_valid else 'âŒ'} {ai_message}")
        
        return ai_valid
    
    def test_vector_store_initialization(self):
        """æµ‹è¯•å‘é‡å­˜å‚¨åˆå§‹åŒ–"""
        print("\nğŸ—„ï¸  æµ‹è¯•å‘é‡å­˜å‚¨åˆå§‹åŒ–...")
        
        # æµ‹è¯•å‘é‡å­˜å‚¨æ˜¯å¦å¯ç”¨
        if self.vector_store.is_available():
            print("   âœ… ChromaDBå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("   âŒ ChromaDBå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        try:
            health = self.vector_store.health_check()
            print(f"   å¥åº·çŠ¶æ€: {health}")
            return health.get("status") == "healthy"
        except Exception as e:
            print(f"   âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def test_embedding_service(self):
        """æµ‹è¯•embeddingæœåŠ¡"""
        print("\nğŸ§  æµ‹è¯•embeddingæœåŠ¡...")
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
        if not self.embedding_service.is_available():
            print("   âŒ EmbeddingæœåŠ¡ä¸å¯ç”¨")
            return False
        
        print(f"   æä¾›å•†: {self.embedding_service.provider}")
        
        # æµ‹è¯•è¿æ¥
        try:
            connection_test = self.embedding_service.test_connection()
            print(f"   è¿æ¥æµ‹è¯•: {connection_test}")
            if not connection_test.get("success", False):
                print(f"   âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {connection_test.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
        except Exception as e:
            print(f"   âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
            return False
        
        # æµ‹è¯•å•ä¸ªæ–‡æœ¬embedding
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯embeddingç”ŸæˆåŠŸèƒ½ã€‚"
        print(f"   æµ‹è¯•æ–‡æœ¬: {test_text}")
        
        try:
            embedding = self.embedding_service.generate_embedding(test_text)
            if embedding:
                print(f"   âœ… å•ä¸ªembeddingç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(embedding)}")
                print(f"   å‰5ä¸ªå€¼: {embedding[:5]}")
            else:
                print("   âŒ å•ä¸ªembeddingç”Ÿæˆå¤±è´¥")
                return False
        except Exception as e:
            print(f"   âŒ å•ä¸ªembeddingç”Ÿæˆå¼‚å¸¸: {e}")
            return False
        
        # æµ‹è¯•æ‰¹é‡embedding
        test_texts = [
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œã€‚",
            "è‡ªç„¶è¯­è¨€å¤„ç†å¤„ç†äººç±»è¯­è¨€ã€‚"
        ]
        
        print(f"   æµ‹è¯•æ‰¹é‡embedding: {len(test_texts)} ä¸ªæ–‡æœ¬")
        
        try:
            embeddings, failed_texts = self.embedding_service.batch_generate_embeddings(
                test_texts, batch_size=2, delay_between_batches=0.5
            )
            
            if embeddings:
                print(f"   âœ… æ‰¹é‡embeddingç”ŸæˆæˆåŠŸ: {len(embeddings)}/{len(test_texts)}")
                if failed_texts:
                    print(f"   âš ï¸  å¤±è´¥æ–‡æœ¬æ•°: {len(failed_texts)}")
            else:
                print("   âŒ æ‰¹é‡embeddingç”Ÿæˆå¤±è´¥")
                return False
                
        except Exception as e:
            print(f"   âŒ æ‰¹é‡embeddingç”Ÿæˆå¼‚å¸¸: {e}")
            return False
        
        return True
    
    def test_collection_management(self):
        """æµ‹è¯•é›†åˆç®¡ç†"""
        print("\nğŸ“š æµ‹è¯•é›†åˆç®¡ç†...")
        
        if not self.group_id:
            print("   âŒ éœ€è¦å…ˆè·å–ç ”ç©¶ç»„ID")
            return False
        
        # æµ‹è¯•åˆ›å»ºé›†åˆ
        print(f"   ä¸ºç ”ç©¶ç»„ {self.group_id} åˆ›å»ºé›†åˆ...")
        success = self.vector_store.create_collection_for_group(self.group_id)
        if success:
            print("   âœ… é›†åˆåˆ›å»ºæˆåŠŸ")
        else:
            print("   âŒ é›†åˆåˆ›å»ºå¤±è´¥")
            return False
        
        # æµ‹è¯•è·å–é›†åˆ
        print("   è·å–é›†åˆ...")
        collection = self.vector_store.get_or_create_collection(self.group_id)
        if collection:
            print(f"   âœ… é›†åˆè·å–æˆåŠŸ: {collection.name}")
        else:
            print("   âŒ é›†åˆè·å–å¤±è´¥")
            return False
        
        # æµ‹è¯•é›†åˆç»Ÿè®¡
        try:
            stats = self.vector_store.get_collection_stats(self.group_id)
            print(f"   é›†åˆç»Ÿè®¡: {stats}")
        except Exception as e:
            print(f"   âš ï¸  é›†åˆç»Ÿè®¡è·å–å¤±è´¥: {e}")
        
        return True
    
    def test_document_storage_and_retrieval(self):
        """æµ‹è¯•æ–‡æ¡£å­˜å‚¨å’Œæ£€ç´¢"""
        print("\nğŸ“„ æµ‹è¯•æ–‡æ¡£å­˜å‚¨å’Œæ£€ç´¢...")
        
        if not self.group_id:
            print("   âŒ éœ€è¦å…ˆè·å–ç ”ç©¶ç»„ID")
            return False
        
        # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
        test_document = """
        äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚

        æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒæ˜¯ä¸€ç§é€šè¿‡ç®—æ³•ä½¿æœºå™¨èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºå†³ç­–æˆ–é¢„æµ‹çš„æŠ€æœ¯ã€‚æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯è®©è®¡ç®—æœºé€šè¿‡å¤§é‡æ•°æ®çš„è®­ç»ƒï¼Œè‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼å’Œè§„å¾‹ã€‚

        æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚

        è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processingï¼ŒNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½å’Œè¯­è¨€å­¦é¢†åŸŸçš„åˆ†æ”¯å­¦ç§‘ã€‚æ­¤é¢†åŸŸæ¢è®¨å¦‚ä½•å¤„ç†åŠè¿ç”¨è‡ªç„¶è¯­è¨€ã€‚
        """
        
        literature_id = f"test_lit_{int(time.time())}"
        print(f"   æµ‹è¯•æ–‡çŒ®ID: {literature_id}")
        
        # 1. æ–‡æœ¬åˆ†å—
        print("   æ­¥éª¤1: æ–‡æœ¬åˆ†å—...")
        chunks = split_text_into_chunks(test_document, chunk_size=300, overlap=50)
        print(f"   âœ… åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªå—")
        
        # 2. å‡†å¤‡chunksæ•°æ®
        print("   æ­¥éª¤2: å‡†å¤‡chunksæ•°æ®...")
        chunks_data = prepare_chunks_for_embedding(
            chunks, literature_id, self.group_id, "äººå·¥æ™ºèƒ½æŠ€æœ¯æ¦‚è¿°"
        )
        print(f"   âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {len(chunks_data)} ä¸ªæ•°æ®å—")
        
        # 3. ç”Ÿæˆembeddings
        print("   æ­¥éª¤3: ç”Ÿæˆembeddings...")
        embeddings, failed_texts = self.embedding_service.batch_generate_embeddings(
            [chunk["text"] for chunk in chunks_data],
            batch_size=3,
            delay_between_batches=0.5
        )
        
        if not embeddings:
            print("   âŒ Embeddingç”Ÿæˆå¤±è´¥")
            return False
        
        print(f"   âœ… Embeddingç”Ÿæˆå®Œæˆ: {len(embeddings)} ä¸ªå‘é‡")
        
        # 4. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        print("   æ­¥éª¤4: å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“...")
        success = self.vector_store.store_document_chunks(
            chunks_data, embeddings, literature_id, self.group_id
        )
        
        if not success:
            print("   âŒ å‘é‡å­˜å‚¨å¤±è´¥")
            return False
        
        print("   âœ… å‘é‡å­˜å‚¨æˆåŠŸ")
        
        # 5. æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢
        print("   æ­¥éª¤5: æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢...")
        
        # ç”ŸæˆæŸ¥è¯¢embedding
        query_text = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
        print(f"   æŸ¥è¯¢æ–‡æœ¬: {query_text}")
        
        query_embedding = self.embedding_service.generate_embedding(query_text)
        if not query_embedding:
            print("   âŒ æŸ¥è¯¢embeddingç”Ÿæˆå¤±è´¥")
            return False
        
        # æ‰§è¡Œæœç´¢
        search_results = self.vector_store.search_similar_chunks(
            query_embedding, self.group_id, literature_id, top_k=3
        )
        
        if search_results:
            print(f"   âœ… æœç´¢æˆåŠŸ: æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœ")
            for i, result in enumerate(search_results):
                print(f"      ç»“æœ {i+1}: ç›¸ä¼¼åº¦ {result.get('similarity', 0):.3f}")
                print(f"         æ–‡æœ¬é¢„è§ˆ: {result.get('text', '')[:100]}...")
        else:
            print("   âŒ æœç´¢å¤±è´¥æˆ–æ— ç»“æœ")
            return False
        
        # 6. æµ‹è¯•åˆ é™¤æ–‡æ¡£
        print("   æ­¥éª¤6: æµ‹è¯•åˆ é™¤æ–‡æ¡£...")
        delete_success = self.vector_store.delete_document_chunks(literature_id, self.group_id)
        if delete_success:
            print("   âœ… æ–‡æ¡£åˆ é™¤æˆåŠŸ")
        else:
            print("   âŒ æ–‡æ¡£åˆ é™¤å¤±è´¥")
            return False
        
        return True
    
    def test_integration_with_api(self):
        """æµ‹è¯•ä¸APIçš„é›†æˆ"""
        print("\nğŸ”— æµ‹è¯•ä¸APIçš„é›†æˆ...")
        
        # ä¸Šä¼ ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶
        print("   ä¸Šä¼ æµ‹è¯•æ–‡ä»¶...")
        test_content = """
        æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åº”ç”¨ç ”ç©¶
        
        æ‘˜è¦ï¼šæœ¬æ–‡æ¢è®¨äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æœ€æ–°è¿›å±•å’Œåº”ç”¨ã€‚
        
        1. å¼•è¨€
        è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œè§£é‡Šè§†è§‰ä¿¡æ¯ã€‚
        
        2. æ·±åº¦å­¦ä¹ åŸºç¡€
        æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å±‚æ¬¡åŒ–è¡¨ç¤ºã€‚
        
        3. å·ç§¯ç¥ç»ç½‘ç»œ
        å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ˜¯è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„æ·±åº¦å­¦ä¹ æ¶æ„ã€‚
        
        4. åº”ç”¨æ¡ˆä¾‹
        æ·±åº¦å­¦ä¹ åœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœã€‚
        
        5. ç»“è®º
        æ·±åº¦å­¦ä¹ æŠ€æœ¯ä¸ºè®¡ç®—æœºè§†è§‰é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„è¿›å±•ã€‚
        """
        
        with tempfile.NamedTemporaryFile(mode='w', suffix=".txt", delete=False, encoding='utf-8') as tmp_file:
            tmp_file.write(test_content)
            tmp_file_path = tmp_file.name
        
        try:
            with open(tmp_file_path, "rb") as f:
                files = {"file": ("integration_test.txt", f, "text/plain")}
                data = {
                    "group_id": self.group_id,
                    "title": "æ·±åº¦å­¦ä¹ æŠ€æœ¯åº”ç”¨ç ”ç©¶"
                }
                
                response = requests.post(
                    f"{BASE_URL}/literature/upload",
                    files=files,
                    data=data,
                    headers=self.get_headers()
                )
            
            if response.status_code == 200:
                result = response.json()
                self.literature_id = result["literature_id"]
                print(f"   âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {self.literature_id}")
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©å¼‚æ­¥å¤„ç†å®Œæˆ
                print("   ç­‰å¾…å¼‚æ­¥å¤„ç†å®Œæˆ...")
                time.sleep(5)
                
                # æµ‹è¯•æœç´¢åŠŸèƒ½
                print("   æµ‹è¯•æœç´¢åŠŸèƒ½...")
                search_data = {
                    "query": "å·ç§¯ç¥ç»ç½‘ç»œçš„åº”ç”¨",
                    "group_id": self.group_id,
                    "top_k": 3
                }
                
                search_response = requests.post(
                    f"{BASE_URL}/literature/search",
                    json=search_data,
                    headers=self.get_headers()
                )
                
                if search_response.status_code == 200:
                    search_results = search_response.json()
                    print(f"   âœ… æœç´¢æˆåŠŸ: æ‰¾åˆ° {len(search_results.get('results', []))} ä¸ªç»“æœ")
                    
                    for i, result in enumerate(search_results.get('results', [])[:2]):
                        print(f"      ç»“æœ {i+1}: {result.get('literature_title', 'N/A')}")
                        print(f"         ç›¸ä¼¼åº¦: {result.get('similarity', 0):.3f}")
                        print(f"         æ–‡æœ¬é¢„è§ˆ: {result.get('text', '')[:80]}...")
                else:
                    print(f"   âŒ æœç´¢å¤±è´¥: {search_response.text}")
                    return False
                
                return True
            else:
                print(f"   âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {response.text}")
                return False
                
        finally:
            if os.path.exists(tmp_file_path):
                try:
                    os.unlink(tmp_file_path)
                except:
                    pass
    
    def test_performance(self):
        """æµ‹è¯•æ€§èƒ½"""
        print("\nâš¡ æµ‹è¯•æ€§èƒ½...")
        
        # æµ‹è¯•embeddingç”Ÿæˆæ€§èƒ½
        test_texts = [f"è¿™æ˜¯ç¬¬{i}ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºæ€§èƒ½æµ‹è¯•ã€‚" for i in range(10)]
        
        print(f"   æµ‹è¯• {len(test_texts)} ä¸ªæ–‡æœ¬çš„embeddingç”Ÿæˆ...")
        start_time = time.time()
        
        embeddings, failed = self.embedding_service.batch_generate_embeddings(
            test_texts, batch_size=5, delay_between_batches=0.1
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        if embeddings:
            print(f"   âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ:")
            print(f"      æ€»æ—¶é—´: {duration:.2f} ç§’")
            print(f"      å¹³å‡æ¯ä¸ª: {duration/len(test_texts):.2f} ç§’")
            print(f"      æˆåŠŸç‡: {len(embeddings)/len(test_texts)*100:.1f}%")
        else:
            print("   âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥")
            return False
        
        return True
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª å‘é‡æ•°æ®åº“åŠŸèƒ½æµ‹è¯•")
        print("="*60)
        
        tests = [
            ("é…ç½®ä¿¡æ¯", self.test_configuration),
            ("å‘é‡å­˜å‚¨åˆå§‹åŒ–", self.test_vector_store_initialization),
            ("EmbeddingæœåŠ¡", self.test_embedding_service),
            ("ç™»å½•", self.login),
            ("è·å–ç ”ç©¶ç»„", self.get_user_groups),
            ("é›†åˆç®¡ç†", self.test_collection_management),
            ("æ–‡æ¡£å­˜å‚¨å’Œæ£€ç´¢", self.test_document_storage_and_retrieval),
            ("APIé›†æˆ", self.test_integration_with_api),
            ("æ€§èƒ½æµ‹è¯•", self.test_performance)
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            try:
                print(f"\n{'='*20} {test_name} {'='*20}")
                if test_func():
                    passed += 1
                    print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            except Exception as e:
                print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰å‘é‡æ•°æ®åº“åŠŸèƒ½æµ‹è¯•é€šè¿‡!")
            print("\nğŸ“‹ åŠŸèƒ½å®ç°æ€»ç»“:")
            print("   âœ… ChromaDBé›†æˆå’Œåˆå§‹åŒ–")
            print("   âœ… Google AI Studio embeddingæœåŠ¡")
            print("   âœ… å‘é‡é›†åˆç®¡ç†")
            print("   âœ… æ–‡æ¡£å—å­˜å‚¨å’Œæ£€ç´¢")
            print("   âœ… ç›¸ä¼¼åº¦æœç´¢")
            print("   âœ… æ‰¹é‡å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–")
            print("   âœ… APIé›†æˆ")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")

def main():
    """ä¸»å‡½æ•°"""
    tester = VectorDatabaseTester()
    tester.run_all_tests()

if __name__ == "__main__":
    main() 