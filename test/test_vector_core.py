#!/usr/bin/env python3
"""
å‘é‡æ•°æ®åº“æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ChromaDBã€Google embeddingã€å‘é‡å­˜å‚¨ç­‰æ ¸å¿ƒåŠŸèƒ½
ä¸ä¾èµ–APIæœåŠ¡å™¨
"""

import os
import sys
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.utils.vector_store import VectorStore
from app.utils.embedding_service import EmbeddingService
from app.utils.text_processor import split_text_into_chunks, prepare_chunks_for_embedding
from app.config import settings

def test_configuration():
    """æµ‹è¯•é…ç½®ä¿¡æ¯"""
    print("âš™ï¸  æµ‹è¯•é…ç½®ä¿¡æ¯...")
    
    print(f"   AIæä¾›å•†: {settings.get_ai_provider()}")
    print(f"   å‘é‡æ•°æ®åº“è·¯å¾„: {settings.VECTOR_DB_PATH}")
    print(f"   é›†åˆå‰ç¼€: {settings.VECTOR_DB_COLLECTION_PREFIX}")
    
    ai_valid, ai_message = settings.validate_ai_config()
    print(f"   AIé…ç½®: {'âœ…' if ai_valid else 'âŒ'} {ai_message}")
    
    return ai_valid

def test_vector_store():
    """æµ‹è¯•å‘é‡å­˜å‚¨"""
    print("\nğŸ—„ï¸  æµ‹è¯•å‘é‡å­˜å‚¨...")
    
    vector_store = VectorStore()
    
    # æµ‹è¯•åˆå§‹åŒ–
    if vector_store.is_available():
        print("   âœ… ChromaDBå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    else:
        print("   âŒ ChromaDBå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
        return False
    
    # æµ‹è¯•å¥åº·æ£€æŸ¥
    try:
        health = vector_store.health_check()
        print(f"   å¥åº·çŠ¶æ€: {health}")
        if health.get("status") != "healthy":
            print("   âŒ å‘é‡å­˜å‚¨å¥åº·æ£€æŸ¥å¤±è´¥")
            return False
    except Exception as e:
        print(f"   âŒ å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
        return False
    
    return True

def test_embedding_service():
    """æµ‹è¯•embeddingæœåŠ¡"""
    print("\nğŸ§  æµ‹è¯•embeddingæœåŠ¡...")
    
    embedding_service = EmbeddingService()
    
    # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
    if not embedding_service.is_available():
        print("   âŒ EmbeddingæœåŠ¡ä¸å¯ç”¨")
        return False
    
    print(f"   æä¾›å•†: {embedding_service.provider}")
    
    # æµ‹è¯•è¿æ¥
    try:
        connection_test = embedding_service.test_connection()
        print(f"   è¿æ¥æµ‹è¯•: {connection_test}")
        if not connection_test.get("success", False):
            print(f"   âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {connection_test.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
    except Exception as e:
        print(f"   âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    # æµ‹è¯•å•ä¸ªæ–‡æœ¬embedding
    test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯embeddingç”ŸæˆåŠŸèƒ½ã€‚"
    print(f"   æµ‹è¯•æ–‡æœ¬: {test_text}")
    
    try:
        embedding = embedding_service.generate_embedding(test_text)
        if embedding:
            print(f"   âœ… å•ä¸ªembeddingç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(embedding)}")
            print(f"   å‰5ä¸ªå€¼: {[f'{x:.4f}' for x in embedding[:5]]}")
        else:
            print("   âŒ å•ä¸ªembeddingç”Ÿæˆå¤±è´¥")
            return False
    except Exception as e:
        print(f"   âŒ å•ä¸ªembeddingç”Ÿæˆå¼‚å¸¸: {e}")
        return False
    
    # æµ‹è¯•æ‰¹é‡embedding
    test_texts = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†å¤„ç†äººç±»è¯­è¨€ã€‚"
    ]
    
    print(f"   æµ‹è¯•æ‰¹é‡embedding: {len(test_texts)} ä¸ªæ–‡æœ¬")
    
    try:
        embeddings, failed_texts = embedding_service.batch_generate_embeddings(
            test_texts, batch_size=2, delay_between_batches=0.5
        )
        
        if embeddings:
            print(f"   âœ… æ‰¹é‡embeddingç”ŸæˆæˆåŠŸ: {len(embeddings)}/{len(test_texts)}")
            if failed_texts:
                print(f"   âš ï¸  å¤±è´¥æ–‡æœ¬æ•°: {len(failed_texts)}")
        else:
            print("   âŒ æ‰¹é‡embeddingç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"   âŒ æ‰¹é‡embeddingç”Ÿæˆå¼‚å¸¸: {e}")
        return False
    
    return True

def test_collection_management():
    """æµ‹è¯•é›†åˆç®¡ç†"""
    print("\nğŸ“š æµ‹è¯•é›†åˆç®¡ç†...")
    
    vector_store = VectorStore()
    test_group_id = "test_group_123"
    
    # æµ‹è¯•åˆ›å»ºé›†åˆ
    print(f"   ä¸ºæµ‹è¯•ç»„ {test_group_id} åˆ›å»ºé›†åˆ...")
    success = vector_store.create_collection_for_group(test_group_id)
    if success:
        print("   âœ… é›†åˆåˆ›å»ºæˆåŠŸ")
    else:
        print("   âŒ é›†åˆåˆ›å»ºå¤±è´¥")
        return False
    
    # æµ‹è¯•è·å–é›†åˆ
    print("   è·å–é›†åˆ...")
    collection = vector_store.get_or_create_collection(test_group_id)
    if collection:
        print(f"   âœ… é›†åˆè·å–æˆåŠŸ: {collection.name}")
    else:
        print("   âŒ é›†åˆè·å–å¤±è´¥")
        return False
    
    # æµ‹è¯•é›†åˆç»Ÿè®¡
    try:
        stats = vector_store.get_collection_stats(test_group_id)
        print(f"   é›†åˆç»Ÿè®¡: {stats}")
    except Exception as e:
        print(f"   âš ï¸  é›†åˆç»Ÿè®¡è·å–å¤±è´¥: {e}")
    
    return True

def test_document_storage_and_retrieval():
    """æµ‹è¯•æ–‡æ¡£å­˜å‚¨å’Œæ£€ç´¢"""
    print("\nğŸ“„ æµ‹è¯•æ–‡æ¡£å­˜å‚¨å’Œæ£€ç´¢...")
    
    vector_store = VectorStore()
    embedding_service = EmbeddingService()
    test_group_id = "test_group_123"
    
    # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
    test_document = """
    äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚

    æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒæ˜¯ä¸€ç§é€šè¿‡ç®—æ³•ä½¿æœºå™¨èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºå†³ç­–æˆ–é¢„æµ‹çš„æŠ€æœ¯ã€‚æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯è®©è®¡ç®—æœºé€šè¿‡å¤§é‡æ•°æ®çš„è®­ç»ƒï¼Œè‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼å’Œè§„å¾‹ã€‚

    æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚

    è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processingï¼ŒNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½å’Œè¯­è¨€å­¦é¢†åŸŸçš„åˆ†æ”¯å­¦ç§‘ã€‚æ­¤é¢†åŸŸæ¢è®¨å¦‚ä½•å¤„ç†åŠè¿ç”¨è‡ªç„¶è¯­è¨€ã€‚
    """
    
    literature_id = f"test_lit_{int(time.time())}"
    print(f"   æµ‹è¯•æ–‡çŒ®ID: {literature_id}")
    
    # 1. æ–‡æœ¬åˆ†å—
    print("   æ­¥éª¤1: æ–‡æœ¬åˆ†å—...")
    chunks = split_text_into_chunks(test_document, chunk_size=300, overlap=50)
    print(f"   âœ… åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªå—")
    
    for i, chunk in enumerate(chunks):
        print(f"      å— {i+1}: {len(chunk)} å­—ç¬¦")
    
    # 2. å‡†å¤‡chunksæ•°æ®
    print("   æ­¥éª¤2: å‡†å¤‡chunksæ•°æ®...")
    chunks_data = prepare_chunks_for_embedding(
        chunks, literature_id, test_group_id, "äººå·¥æ™ºèƒ½æŠ€æœ¯æ¦‚è¿°"
    )
    print(f"   âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {len(chunks_data)} ä¸ªæ•°æ®å—")
    
    # 3. ç”Ÿæˆembeddings
    print("   æ­¥éª¤3: ç”Ÿæˆembeddings...")
    embeddings, failed_texts = embedding_service.batch_generate_embeddings(
        [chunk["text"] for chunk in chunks_data],
        batch_size=2,
        delay_between_batches=1.0
    )
    
    if not embeddings:
        print("   âŒ Embeddingç”Ÿæˆå¤±è´¥")
        return False
    
    print(f"   âœ… Embeddingç”Ÿæˆå®Œæˆ: {len(embeddings)} ä¸ªå‘é‡")
    print(f"   å‘é‡ç»´åº¦: {len(embeddings[0]) if embeddings else 0}")
    
    # 4. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    print("   æ­¥éª¤4: å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“...")
    success = vector_store.store_document_chunks(
        chunks_data, embeddings, literature_id, test_group_id
    )
    
    if not success:
        print("   âŒ å‘é‡å­˜å‚¨å¤±è´¥")
        return False
    
    print("   âœ… å‘é‡å­˜å‚¨æˆåŠŸ")
    
    # 5. æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢
    print("   æ­¥éª¤5: æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢...")
    
    # ç”ŸæˆæŸ¥è¯¢embedding
    query_text = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
    print(f"   æŸ¥è¯¢æ–‡æœ¬: {query_text}")
    
    query_embedding = embedding_service.generate_embedding(query_text)
    if not query_embedding:
        print("   âŒ æŸ¥è¯¢embeddingç”Ÿæˆå¤±è´¥")
        return False
    
    # æ‰§è¡Œæœç´¢
    search_results = vector_store.search_similar_chunks(
        query_embedding, test_group_id, literature_id, top_k=3
    )
    
    if search_results:
        print(f"   âœ… æœç´¢æˆåŠŸ: æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœ")
        for i, result in enumerate(search_results):
            similarity = result.get('similarity', result.get('distance', 0))
            print(f"      ç»“æœ {i+1}: ç›¸ä¼¼åº¦ {similarity:.3f}")
            print(f"         æ–‡æœ¬é¢„è§ˆ: {result.get('text', '')[:100]}...")
    else:
        print("   âŒ æœç´¢å¤±è´¥æˆ–æ— ç»“æœ")
        return False
    
    # 6. æµ‹è¯•åˆ é™¤æ–‡æ¡£
    print("   æ­¥éª¤6: æµ‹è¯•åˆ é™¤æ–‡æ¡£...")
    delete_success = vector_store.delete_document_chunks(literature_id, test_group_id)
    if delete_success:
        print("   âœ… æ–‡æ¡£åˆ é™¤æˆåŠŸ")
    else:
        print("   âŒ æ–‡æ¡£åˆ é™¤å¤±è´¥")
        return False
    
    return True

def test_performance():
    """æµ‹è¯•æ€§èƒ½"""
    print("\nâš¡ æµ‹è¯•æ€§èƒ½...")
    
    embedding_service = EmbeddingService()
    
    # æµ‹è¯•embeddingç”Ÿæˆæ€§èƒ½
    test_texts = [f"è¿™æ˜¯ç¬¬{i}ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºæ€§èƒ½æµ‹è¯•ã€‚åŒ…å«ä¸€äº›ä¸­æ–‡å†…å®¹å’Œæ•°å­—{i}ã€‚" for i in range(5)]
    
    print(f"   æµ‹è¯• {len(test_texts)} ä¸ªæ–‡æœ¬çš„embeddingç”Ÿæˆ...")
    start_time = time.time()
    
    embeddings, failed = embedding_service.batch_generate_embeddings(
        test_texts, batch_size=3, delay_between_batches=0.5
    )
    
    end_time = time.time()
    duration = end_time - start_time
    
    if embeddings:
        print(f"   âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"      æ€»æ—¶é—´: {duration:.2f} ç§’")
        print(f"      å¹³å‡æ¯ä¸ª: {duration/len(test_texts):.2f} ç§’")
        print(f"      æˆåŠŸç‡: {len(embeddings)/len(test_texts)*100:.1f}%")
    else:
        print("   âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥")
        return False
    
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å‘é‡æ•°æ®åº“æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
    print("="*50)
    
    tests = [
        ("é…ç½®ä¿¡æ¯", test_configuration),
        ("å‘é‡å­˜å‚¨åˆå§‹åŒ–", test_vector_store),
        ("EmbeddingæœåŠ¡", test_embedding_service),
        ("é›†åˆç®¡ç†", test_collection_management),
        ("æ–‡æ¡£å­˜å‚¨å’Œæ£€ç´¢", test_document_storage_and_retrieval),
        ("æ€§èƒ½æµ‹è¯•", test_performance)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*20} {test_name} {'='*20}")
            if test_func():
                passed += 1
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰å‘é‡æ•°æ®åº“æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡!")
        print("\nğŸ“‹ åŠŸèƒ½å®ç°æ€»ç»“:")
        print("   âœ… ChromaDBé›†æˆå’Œåˆå§‹åŒ–")
        print("   âœ… Google AI Studio embeddingæœåŠ¡")
        print("   âœ… å‘é‡é›†åˆç®¡ç†")
        print("   âœ… æ–‡æ¡£å—å­˜å‚¨å’Œæ£€ç´¢")
        print("   âœ… ç›¸ä¼¼åº¦æœç´¢")
        print("   âœ… æ‰¹é‡å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        print("\nğŸ’¡ å¯èƒ½çš„é—®é¢˜:")
        print("   - æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„GOOGLE_API_KEYæ˜¯å¦æ­£ç¡®é…ç½®")
        print("   - ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œå¯ä»¥è®¿é—®Google AIæœåŠ¡")
        print("   - æ£€æŸ¥ChromaDBæ˜¯å¦æ­£ç¡®å®‰è£…")

if __name__ == "__main__":
    main() 