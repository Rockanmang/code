# RAGæŠ€æœ¯é€‰å‹ä¸æ¶æ„å†³ç­–

## ğŸ¯ è®¾è®¡åŸåˆ™

### 1. ç®€å•ä¼˜å…ˆ (Simplicity First)
- ä¼˜å…ˆé€‰æ‹©ç®€å•ã€ç¨³å®šçš„æŠ€æœ¯æ–¹æ¡ˆ
- é¿å…è¿‡åº¦å·¥ç¨‹åŒ–å’Œå¤æ‚æŠ½è±¡
- ç¡®ä¿ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§

### 2. æ€§èƒ½ä¼˜åŒ– (Performance Optimization)
- ç¼“å­˜ç­–ç•¥æœ€å¤§åŒ–å“åº”é€Ÿåº¦
- å¼‚æ­¥å¤„ç†æå‡å¹¶å‘èƒ½åŠ›
- æ™ºèƒ½æ£€ç´¢å‡å°‘è®¡ç®—å¼€é”€

### 3. å¯æ‰©å±•æ€§ (Scalability)
- æ¨¡å—åŒ–è®¾è®¡æ”¯æŒåŠŸèƒ½æ‰©å±•
- æ’ä»¶å¼æ¶æ„æ”¯æŒç®—æ³•åˆ‡æ¢
- é…ç½®é©±åŠ¨æ”¯æŒå‚æ•°è°ƒä¼˜

### 4. ç”¨æˆ·ä½“éªŒ (User Experience)
- å¿«é€Ÿå“åº”æ—¶é—´
- å‡†ç¡®çš„ç­”æ¡ˆè´¨é‡
- å‹å¥½çš„é”™è¯¯å¤„ç†

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„å†³ç­–

### 1. RAGç®¡é“è®¾è®¡

#### é€‰æ‹©ï¼šç»å…¸RAGæ¶æ„ + ä¼˜åŒ–
```
é—®é¢˜è¾“å…¥ â†’ Embedding â†’ æ£€ç´¢ â†’ é‡æ’åº â†’ ä¸Šä¸‹æ–‡æ„å»º â†’ LLMç”Ÿæˆ â†’ åå¤„ç†
```

**ç†ç”±**:
- ç®€å•ç›´è§‚ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤
- æ¯ä¸ªç¯èŠ‚å¯ç‹¬ç«‹ä¼˜åŒ–
- æˆç†Ÿçš„è®¾è®¡æ¨¡å¼ï¼Œé£é™©è¾ƒä½

**æ›¿ä»£æ–¹æ¡ˆ**: 
- é«˜çº§RAGï¼ˆå¦‚HyDEã€CoTç­‰ï¼‰- å¤æ‚åº¦è¿‡é«˜
- End-to-endè®­ç»ƒ - èµ„æºè¦æ±‚è¿‡é«˜

### 2. LLMæœåŠ¡é€‰æ‹©

#### é€‰æ‹©ï¼šGoogle Gemini API
**ä¼˜åŠ¿**:
- å·²æœ‰é›†æˆåŸºç¡€
- å…è´¹é¢åº¦å……è¶³
- å¤šè¯­è¨€æ”¯æŒå¥½
- APIç¨³å®šæ€§é«˜

**è€ƒè™‘å› ç´ **:
- æˆæœ¬æ§åˆ¶
- å“åº”é€Ÿåº¦
- è´¨é‡ç¨³å®šæ€§
- ç»´æŠ¤å¤æ‚åº¦

### 3. å‘é‡æ£€ç´¢ç­–ç•¥

#### é€‰æ‹©ï¼šChromaDB + è¯­ä¹‰æ£€ç´¢ + å…³é”®è¯è¡¥å……
**æ ¸å¿ƒç­–ç•¥**:
- ä¸»è¦ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
- è¡¥å……å…³é”®è¯åŒ¹é…æå‡å¬å›
- ç»“æœé‡æ’åºä¼˜åŒ–ç²¾åº¦

**å®ç°ç»†èŠ‚**:
```python
def retrieve_chunks(question, literature_id, top_k=10):
    # 1. å‘é‡æ£€ç´¢ï¼ˆä¸»è¦æ–¹æ³•ï¼‰
    vector_results = vector_search(question_embedding, top_k*2)
    
    # 2. å…³é”®è¯æ£€ç´¢ï¼ˆè¡¥å……æ–¹æ³•ï¼‰
    keyword_results = keyword_search(extract_keywords(question))
    
    # 3. ç»“æœèåˆå’Œé‡æ’åº
    merged_results = merge_and_rerank(vector_results, keyword_results)
    
    return merged_results[:top_k]
```

### 4. å¯¹è¯å†å²ç®¡ç†

#### é€‰æ‹©ï¼šæ»‘åŠ¨çª—å£ + å…³é”®ä¿¡æ¯æå–
**ç­–ç•¥**:
- ä¿ç•™æœ€è¿‘5-10è½®å¯¹è¯
- æå–å†å²ä¸­çš„å…³é”®å®ä½“å’Œæ¦‚å¿µ
- æ™ºèƒ½å‹ç¼©è¶…é•¿å¯¹è¯

**æ•°æ®ç»“æ„**:
```python
class ConversationContext:
    recent_turns: List[QATurn]  # æœ€è¿‘è½®æ¬¡
    key_entities: Dict[str, float]  # å…³é”®å®ä½“æƒé‡
    topic_summary: str  # è¯é¢˜æ‘˜è¦
    context_tokens: int  # ä¸Šä¸‹æ–‡é•¿åº¦
```

### 5. æç¤ºè¯å·¥ç¨‹

#### é€‰æ‹©ï¼šæ¨¡æ¿åŒ– + åŠ¨æ€ç»„è£…
**è®¾è®¡ç†å¿µ**:
- åŸºç¡€æ¨¡æ¿ä¿è¯ç¨³å®šæ€§
- åŠ¨æ€å†…å®¹ç¡®ä¿ç›¸å…³æ€§
- åˆ†å±‚è®¾è®¡æ”¯æŒä¸ªæ€§åŒ–

**æ¨¡æ¿ç»“æ„**:
```python
PROMPT_TEMPLATE = """
{system_role}

{context_section}

{conversation_history}

{current_question}

{output_format}
"""
```

---

## ğŸ”§ å…³é”®æŠ€æœ¯é€‰æ‹©

### 1. ç¼“å­˜ç­–ç•¥

#### é€‰æ‹©ï¼šå¤šå±‚ç¼“å­˜æ¶æ„
```python
# L1: å†…å­˜ç¼“å­˜ï¼ˆæœ€çƒ­æ•°æ®ï¼‰
embedding_cache = TTLCache(maxsize=1000, ttl=3600)

# L2: åº”ç”¨ç¼“å­˜ï¼ˆä¸­ç­‰çƒ­åº¦ï¼‰
answer_cache = TTLCache(maxsize=500, ttl=1800)

# L3: æŒä¹…åŒ–ç¼“å­˜ï¼ˆå†·æ•°æ®ï¼‰
persistent_cache = SQLiteCache(db_path="cache.db")
```

**ç¼“å­˜é”®è®¾è®¡**:
```python
def generate_cache_key(question, literature_id, context_hash):
    return f"qa:{hash(question)}:{literature_id}:{context_hash[:8]}"
```

### 2. å¼‚æ­¥å¤„ç†æ¶æ„

#### é€‰æ‹©ï¼šFastAPI + asyncio
**å¤„ç†æµç¨‹**:
```python
async def process_question(request: QARequest):
    # å¹¶è¡Œæ‰§è¡Œembeddingå’Œå†å²æ£€ç´¢
    embedding_task = asyncio.create_task(
        embedding_service.generate_query_embedding(request.question)
    )
    history_task = asyncio.create_task(
        conversation_manager.get_relevant_history(request.session_id)
    )
    
    # ç­‰å¾…å¹¶è¡Œä»»åŠ¡å®Œæˆ
    embedding, history = await asyncio.gather(embedding_task, history_task)
    
    # é¡ºåºæ‰§è¡Œæ£€ç´¢å’Œç”Ÿæˆ
    chunks = await vector_store.search_similar_chunks(embedding, ...)
    answer = await llm_service.generate_answer(...)
    
    return answer
```

### 3. é”™è¯¯å¤„ç†å’Œé™çº§

#### é€‰æ‹©ï¼šç†”æ–­å™¨ + å¤šçº§é™çº§
**ç†”æ–­å™¨å®ç°**:
```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, recovery_timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
        self.last_failure_time = None
```

**é™çº§ç­–ç•¥**:
1. ä¼˜å…ˆä½¿ç”¨ç¼“å­˜ç­”æ¡ˆ
2. è¿”å›ç›¸å…³æ–‡æ¡£å—ï¼ˆæ— AIæ€»ç»“ï¼‰
3. æä¾›æœç´¢å»ºè®®
4. è¿”å›é¢„è®¾å›ç­”

### 4. è´¨é‡ä¿è¯æœºåˆ¶

#### é€‰æ‹©ï¼šå¤šç»´åº¦éªŒè¯ + ç½®ä¿¡åº¦è¯„ä¼°
**éªŒè¯ç»´åº¦**:
```python
class AnswerQualityChecker:
    def evaluate_answer(self, question, answer, sources):
        scores = {
            'relevance': self._check_relevance(question, answer),
            'completeness': self._check_completeness(answer),
            'accuracy': self._check_source_accuracy(answer, sources),
            'coherence': self._check_coherence(answer),
            'safety': self._check_safety(answer)
        }
        
        overall_confidence = self._calculate_confidence(scores)
        return scores, overall_confidence
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. æ£€ç´¢ä¼˜åŒ–

#### åˆ†å±‚æ£€ç´¢ç­–ç•¥
```python
class HierarchicalRetrieval:
    def retrieve(self, question, literature_id, top_k=5):
        # ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿç²—æ£€ç´¢ï¼ˆå¤§èŒƒå›´ï¼‰
        rough_candidates = self.rough_search(question, top_k*4)
        
        # ç¬¬äºŒå±‚ï¼šç²¾ç¡®é‡æ’åºï¼ˆå°èŒƒå›´ï¼‰
        precise_results = self.precise_rerank(question, rough_candidates)
        
        # ç¬¬ä¸‰å±‚ï¼šä¸Šä¸‹æ–‡ä¼˜åŒ–ï¼ˆæœ€ç»ˆç»“æœï¼‰
        optimized_results = self.context_optimize(precise_results[:top_k])
        
        return optimized_results
```

### 2. æç¤ºè¯ä¼˜åŒ–

#### åŠ¨æ€é•¿åº¦è°ƒæ•´
```python
def optimize_prompt_length(context_chunks, max_tokens=3000):
    # æŒ‰é‡è¦æ€§æ’åº
    sorted_chunks = sort_by_relevance_score(context_chunks)
    
    # åŠ¨æ€æ·»åŠ ç›´åˆ°è¾¾åˆ°tokené™åˆ¶
    selected_chunks = []
    current_tokens = base_prompt_tokens
    
    for chunk in sorted_chunks:
        chunk_tokens = estimate_tokens(chunk.text)
        if current_tokens + chunk_tokens <= max_tokens:
            selected_chunks.append(chunk)
            current_tokens += chunk_tokens
        else:
            break
    
    return selected_chunks
```

### 3. å†…å­˜ç®¡ç†

#### æ™ºèƒ½åƒåœ¾å›æ”¶
```python
class MemoryManager:
    def __init__(self):
        self.max_memory_mb = 1024
        self.cleanup_threshold = 0.8
    
    def check_and_cleanup(self):
        current_usage = self.get_memory_usage()
        if current_usage > self.max_memory_mb * self.cleanup_threshold:
            self.cleanup_old_sessions()
            self.clear_expired_cache()
            gc.collect()
```

---

## ğŸ”’ å®‰å…¨å’Œéšç§

### 1. è¾“å…¥éªŒè¯
```python
class InputValidator:
    def validate_question(self, question: str) -> bool:
        # é•¿åº¦æ£€æŸ¥
        if len(question) > 1000:
            raise ValueError("é—®é¢˜è¿‡é•¿")
        
        # å†…å®¹å®‰å…¨æ£€æŸ¥
        if self.contains_unsafe_content(question):
            raise ValueError("é—®é¢˜åŒ…å«ä¸å½“å†…å®¹")
        
        # æ³¨å…¥æ”»å‡»æ£€æŸ¥
        if self.detect_injection_attempt(question):
            raise ValueError("æ£€æµ‹åˆ°æ³¨å…¥æ”»å‡»å°è¯•")
        
        return True
```

### 2. æ•°æ®è„±æ•
```python
def sanitize_response(response: QAResponse) -> QAResponse:
    # ç§»é™¤æ•æ„Ÿä¿¡æ¯
    response.answer = remove_sensitive_patterns(response.answer)
    
    # è„±æ•å¼•ç”¨æ¥æº
    for source in response.sources:
        source.text = mask_personal_info(source.text)
    
    return response
```

---

## ğŸ“ˆ ç›‘æ§å’Œå¯è§‚æµ‹æ€§

### 1. å…³é”®æŒ‡æ ‡ç›‘æ§
```python
class RAGMetrics:
    def __init__(self):
        self.response_times = []
        self.cache_hit_rates = {}
        self.error_counts = defaultdict(int)
        self.quality_scores = []
    
    def record_qa_session(self, session_data):
        self.response_times.append(session_data.response_time)
        self.quality_scores.append(session_data.quality_score)
        
        if session_data.cache_hit:
            self.cache_hit_rates['hits'] += 1
        else:
            self.cache_hit_rates['misses'] += 1
```

### 2. æ—¥å¿—è®°å½•
```python
import structlog

logger = structlog.get_logger()

async def process_question(request: QARequest):
    session_id = generate_session_id()
    
    logger.info(
        "qa_request_started",
        session_id=session_id,
        question_length=len(request.question),
        literature_id=request.literature_id,
        user_id=request.user_id
    )
    
    try:
        # å¤„ç†é€»è¾‘...
        
        logger.info(
            "qa_request_completed",
            session_id=session_id,
            response_time=response_time,
            chunks_retrieved=len(chunks),
            answer_length=len(answer),
            confidence_score=confidence
        )
        
    except Exception as e:
        logger.error(
            "qa_request_failed",
            session_id=session_id,
            error_type=type(e).__name__,
            error_message=str(e)
        )
        raise
```

---

## ğŸ”„ æŒç»­ä¼˜åŒ–è®¡åˆ’

### 1. A/Bæµ‹è¯•æ¡†æ¶
```python
class ABTestManager:
    def __init__(self):
        self.experiments = {}
        
    def run_experiment(self, user_id: str, experiment_name: str):
        # ç”¨æˆ·åˆ†ç»„
        group = self.get_user_group(user_id, experiment_name)
        
        # è·å–å¯¹åº”é…ç½®
        config = self.get_experiment_config(experiment_name, group)
        
        return config
```

### 2. åé¦ˆå­¦ä¹ æœºåˆ¶
```python
class FeedbackLearner:
    def collect_feedback(self, session_id: str, rating: int, comment: str):
        # å­˜å‚¨ç”¨æˆ·åé¦ˆ
        feedback = UserFeedback(
            session_id=session_id,
            rating=rating,
            comment=comment,
            timestamp=datetime.now()
        )
        
        # åˆ†æåé¦ˆæ¨¡å¼
        self.analyze_feedback_patterns()
        
        # æ›´æ–°æ¨¡å‹å‚æ•°
        self.update_retrieval_parameters()
```

è¿™ä¸ªæŠ€æœ¯é€‰å‹æ–‡æ¡£ç¡®ä¿äº†RAGç³»ç»Ÿçš„æŠ€æœ¯å†³ç­–æœ‰æ®å¯ä¾ï¼Œæ¶æ„æ¸…æ™°ï¼Œå¹¶ä¸ºåç»­ä¼˜åŒ–æä¾›äº†æ˜ç¡®æ–¹å‘ã€‚ 